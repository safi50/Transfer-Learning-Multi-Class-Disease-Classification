{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"6442aade","cell_type":"code","source":"# ============================================================================\n# DOWNLOAD DATASET FROM GOOGLE DRIVE\n# ============================================================================\n\n# Install required package for Google Drive download\n!pip install -q gdown\n!pip install timm\n!pip install torch torchvision pandas numpy matplotlib seaborn scikit-learn \n\n\nimport gdown\nimport os\nimport zipfile\n\n# Google Drive file ID (extracted from the sharing link)\nfile_id = \"1UrEdiiUhYSfwOqdZUa82AeEixERQaHlp\"\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\n# Download the dataset\noutput_file = \"final_project_resources.zip\"\nprint(\"ðŸ“¥ Downloading dataset from Google Drive...\")\ngdown.download(url, output_file, quiet=False)\n\n# Extract the dataset\nprint(\"\\nðŸ“¦ Extracting dataset...\")\nwith zipfile.ZipFile(output_file, 'r') as zip_ref:\n    zip_ref.extractall(\"/kaggle/working/\")\n\nprint(\"âœ… Dataset downloaded and extracted successfully!\")\nprint(f\"âœ… Dataset location: /kaggle/working/final_project_resources/\")\n\n# Clean up zip file\nos.remove(output_file)\nprint(\"âœ… Cleanup complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T04:58:48.457841Z","iopub.execute_input":"2025-12-31T04:58:48.458575Z","iopub.status.idle":"2025-12-31T04:59:01.155467Z","shell.execute_reply.started":"2025-12-31T04:58:48.458540Z","shell.execute_reply":"2025-12-31T04:59:01.154566Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nðŸ“¥ Downloading dataset from Google Drive...\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1UrEdiiUhYSfwOqdZUa82AeEixERQaHlp\nFrom (redirected): https://drive.google.com/uc?id=1UrEdiiUhYSfwOqdZUa82AeEixERQaHlp&confirm=t&uuid=d9866079-6685-4466-9d83-1edf827b1057\nTo: /kaggle/working/final_project_resources.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.2M/66.2M [00:00<00:00, 271MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ“¦ Extracting dataset...\nâœ… Dataset downloaded and extracted successfully!\nâœ… Dataset location: /kaggle/working/final_project_resources/\nâœ… Cleanup complete\n","output_type":"stream"}],"execution_count":1},{"id":"309d2276-08e0-4140-ac04-c7ce47fb9196","cell_type":"code","source":"# ============================================================================\n# DOWNLOAD FILE FROM GOOGLE DRIVE IN KAGGLE\n# ============================================================================\n\nimport os\n\n# Install gdown if not already installed\ntry:\n    import gdown\nexcept ImportError:\n    print(\"Installing gdown...\")\n    !pip install -q gdown\n    import gdown\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Google Drive file ID (extracted from your link)\nFILE_ID = \"1z-AGUKsfpabqDQBrTCIqgopmb-AnWLBy\"\n\n# Output file name (change this to whatever you want to name the file)\nOUTPUT_FILE = \"resnet18.pth\"  # or .zip, .pt, .csv, etc.\n\n# Download directory\nDOWNLOAD_DIR = \"/kaggle/working\"\n\n# ============================================================================\n# DOWNLOAD FILE\n# ============================================================================\n\nprint(\"=\"*70)\nprint(\"DOWNLOADING FILE FROM GOOGLE DRIVE\")\nprint(\"=\"*70)\n\n# Construct the download URL\nurl = f\"https://drive.google.com/uc?id={FILE_ID}\"\n\n# Full output path\noutput_path = os.path.join(DOWNLOAD_DIR, OUTPUT_FILE)\n\nprint(f\"\\nDownloading to: {output_path}\")\nprint(\"Please wait...\\n\")\n\n# Download the file\ngdown.download(url, output_path, quiet=False)\n\n# Check if download was successful\nif os.path.exists(output_path):\n    file_size = os.path.getsize(output_path) / (1024 * 1024)  # Size in MB\n    print(f\"\\nâœ… Download complete!\")\n    print(f\"   File: {output_path}\")\n    print(f\"   Size: {file_size:.2f} MB\")\nelse:\n    print(\"\\nâŒ Download failed!\")\n    print(\"   The file might be private or the link is incorrect.\")\n\n# ============================================================================\n# IF IT'S A ZIP FILE, EXTRACT IT (OPTIONAL)\n# ============================================================================\n\n# Uncomment the code below if you downloaded a .zip file\n\n\"\"\"\nif OUTPUT_FILE.endswith('.zip'):\n    print(f\"\\n{'='*70}\")\n    print(\"EXTRACTING ZIP FILE\")\n    print(f\"{'='*70}\\n\")\n    \n    import zipfile\n    \n    extract_dir = os.path.join(DOWNLOAD_DIR, \"extracted\")\n    \n    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_dir)\n    \n    print(f\"âœ… Extracted to: {extract_dir}\")\n    \n    # List extracted files\n    print(\"\\nExtracted files:\")\n    for root, dirs, files in os.walk(extract_dir):\n        for file in files:\n            print(f\"   {os.path.join(root, file)}\")\n    \n    # Optional: Remove zip file after extraction\n    # os.remove(output_path)\n    # print(f\"\\nðŸ—‘ï¸ Removed zip file: {output_path}\")\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… DONE!\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T09:56:06.233077Z","iopub.execute_input":"2025-12-31T09:56:06.233741Z","iopub.status.idle":"2025-12-31T09:56:09.176886Z","shell.execute_reply.started":"2025-12-31T09:56:06.233710Z","shell.execute_reply":"2025-12-31T09:56:09.176124Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nDOWNLOADING FILE FROM GOOGLE DRIVE\n======================================================================\n\nDownloading to: /kaggle/working/resnet18.pth\nPlease wait...\n\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1z-AGUKsfpabqDQBrTCIqgopmb-AnWLBy\nFrom (redirected): https://drive.google.com/uc?id=1z-AGUKsfpabqDQBrTCIqgopmb-AnWLBy&confirm=t&uuid=5adc9a50-5be0-4155-916c-e8858a314eec\nTo: /kaggle/working/resnet18.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45.0M/45.0M [00:00<00:00, 65.5MB/s]","output_type":"stream"},{"name":"stdout","text":"\nâœ… Download complete!\n   File: /kaggle/working/resnet18.pth\n   Size: 42.89 MB\n\n======================================================================\nâœ… DONE!\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":114},{"id":"5e35bb2f","cell_type":"code","source":"# Install required packages (run once)\n# Uncomment the lines below if packages are not installed\n\n# !pip install timm opencv-python tqdm scikit-learn pandas matplotlib pillow\n# !pip install torch torchvision  # If not already installed\n\nprint(\"âœ… Check package imports in the next cell\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T04:59:01.157668Z","iopub.execute_input":"2025-12-31T04:59:01.158033Z","iopub.status.idle":"2025-12-31T04:59:01.163077Z","shell.execute_reply.started":"2025-12-31T04:59:01.158004Z","shell.execute_reply":"2025-12-31T04:59:01.162178Z"}},"outputs":[{"name":"stdout","text":"âœ… Check package imports in the next cell\n","output_type":"stream"}],"execution_count":2},{"id":"5087ce6b","cell_type":"markdown","source":"## ðŸ“¦ Installation Requirements\n\n","metadata":{}},{"id":"8ceaa2e5","cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\nimport timm  # For Swin Transformer and Vision Transformer\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\nimport cv2\nfrom tqdm.auto import tqdm\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Device configuration - prioritize CUDA for Kaggle with multi-GPU support\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    torch.cuda.manual_seed_all(42)\n    num_gpus = torch.cuda.device_count()\n    print(f\"Using device: CUDA\")\n    print(f\"Number of GPUs available: {num_gpus}\")\n    for i in range(num_gpus):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        print(f\"  GPU {i} Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n    if num_gpus > 1:\n        print(f\"\\nðŸš€ Multi-GPU training enabled! Using {num_gpus} GPUs with DataParallel\")\n    use_multi_gpu = num_gpus > 1\nelif torch.backends.mps.is_available():\n    device = torch.device(\"mps\")\n    print(f\"Using device: MPS (Apple Silicon GPU)\")\n    use_multi_gpu = False\nelse:\n    device = torch.device(\"cpu\")\n    print(f\"Using device: CPU\")\n    use_multi_gpu = False\n    \nprint(f\"PyTorch version: {torch.__version__}\")\n\n# Define file paths for Kaggle\nbase_dir = \"/kaggle/working/final_project_resources\"\ntrain_csv = os.path.join(base_dir, \"train.csv\")\nval_csv = os.path.join(base_dir, \"val.csv\")\n\noffsite_test_csv = os.path.join(base_dir, \"offsite_test.csv\")\nprint(f\"Base directory: {base_dir}\")\n\ntrain_img_dir = os.path.join(base_dir, \"images/train\")\nprint(\"\\nâœ… File paths configured for Kaggle\")\n\nval_img_dir = os.path.join(base_dir, \"images/val\")\n\noffsite_test_img_dir = os.path.join(base_dir, \"images/offsite_test\")\nonsite_test_img_dir = os.path.join(base_dir, \"images/onsite_test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T04:59:01.164305Z","iopub.execute_input":"2025-12-31T04:59:01.164626Z","iopub.status.idle":"2025-12-31T04:59:06.384880Z","shell.execute_reply.started":"2025-12-31T04:59:01.164592Z","shell.execute_reply":"2025-12-31T04:59:06.384161Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using device: CUDA\nNumber of GPUs available: 1\n  GPU 0: Tesla P100-PCIE-16GB\n  GPU 0 Memory: 17.06 GB\nPyTorch version: 2.8.0+cu126\nBase directory: /kaggle/working/final_project_resources\n\nâœ… File paths configured for Kaggle\n","output_type":"stream"}],"execution_count":3},{"id":"f229e904","cell_type":"code","source":"# Analyze dataset statistics and class distribution\ndef analyze_dataset(csv_file, dataset_name=\"Dataset\"):\n    \"\"\"Analyze class distribution in the dataset\"\"\"\n    df = pd.read_csv(csv_file)\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"{dataset_name} Statistics\")\n    print(f\"{'='*70}\")\n    print(f\"Total images: {len(df)}\")\n    \n    disease_names = [\"D (DR)\", \"G (Glaucoma)\", \"A (AMD)\"]\n    class_cols = df.columns[1:4]  # Assuming columns are: id, D, G, A\n    \n    for i, (col, disease) in enumerate(zip(class_cols, disease_names)):\n        positive = df[col].sum()\n        negative = len(df) - positive\n        pos_ratio = positive / len(df) * 100\n        \n        print(f\"\\n{disease}:\")\n        print(f\"  Positive: {positive:4d} ({pos_ratio:5.2f}%)\")\n        print(f\"  Negative: {negative:4d} ({100-pos_ratio:5.2f}%)\")\n        print(f\"  Ratio (Pos:Neg): 1:{negative/max(positive, 1):.2f}\")\n    \n    return df\n\n\ndef calculate_class_weights(csv_file):\n    \"\"\"\n    Calculate class weights for handling imbalanced dataset\n    Uses inverse frequency weighting\n    \"\"\"\n    df = pd.read_csv(csv_file)\n    class_cols = df.columns[1:4]  # D, G, A columns\n    \n    weights = []\n    for col in class_cols:\n        positive = df[col].sum()\n        negative = len(df) - positive\n        \n        # Calculate positive weight (inverse frequency)\n        # Higher weight for minority class\n        pos_weight = negative / max(positive, 1)\n        weights.append(pos_weight)\n    \n    weights_tensor = torch.tensor(weights, dtype=torch.float32)\n    \n    print(f\"\\n{'='*70}\")\n    print(\"CLASS WEIGHTS (for weighted BCE loss)\")\n    print(f\"{'='*70}\")\n    disease_names = [\"D (DR)\", \"G (Glaucoma)\", \"A (AMD)\"]\n    for disease, weight in zip(disease_names, weights):\n        print(f\"  {disease}: {weight:.4f}\")\n    print(f\"{'='*70}\\n\")\n    \n    return weights_tensor\n\n\n# Analyze all datasets\ntrain_df = analyze_dataset(train_csv, \"Training Set\")\nval_df = analyze_dataset(val_csv, \"Validation Set\")\noffsite_test_df = analyze_dataset(offsite_test_csv, \"Offsite Test Set\")\n\n# Calculate class weights from training data\nclass_weights = calculate_class_weights(train_csv)\n\nprint(f\"\\n{'='*70}\")\nprint(\"AUGMENTATION STRATEGY\")\nprint(f\"{'='*70}\")\nprint(f\"Original training images: {len(train_df)}\")\nprint(f\"With augmentation (random transforms applied on-the-fly):\")\nprint(f\"  - Each epoch sees different augmented versions\")\nprint(f\"  - Effective dataset size: {len(train_df)} Ã— augmentation variations\")\nprint(f\"  - Augmentation includes: rotation, flips, crops, color jitter,\")\nprint(f\"    affine transforms, shear, grayscale, elastic transforms\")\nprint(f\"{'='*70}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T04:59:06.385746Z","iopub.execute_input":"2025-12-31T04:59:06.386016Z","iopub.status.idle":"2025-12-31T04:59:06.412606Z","shell.execute_reply.started":"2025-12-31T04:59:06.385980Z","shell.execute_reply":"2025-12-31T04:59:06.411919Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nTraining Set Statistics\n======================================================================\nTotal images: 800\n\nD (DR):\n  Positive:  517 (64.62%)\n  Negative:  283 (35.38%)\n  Ratio (Pos:Neg): 1:0.55\n\nG (Glaucoma):\n  Positive:  163 (20.38%)\n  Negative:  637 (79.62%)\n  Ratio (Pos:Neg): 1:3.91\n\nA (AMD):\n  Positive:  142 (17.75%)\n  Negative:  658 (82.25%)\n  Ratio (Pos:Neg): 1:4.63\n\n======================================================================\nValidation Set Statistics\n======================================================================\nTotal images: 200\n\nD (DR):\n  Positive:  109 (54.50%)\n  Negative:   91 (45.50%)\n  Ratio (Pos:Neg): 1:0.83\n\nG (Glaucoma):\n  Positive:   58 (29.00%)\n  Negative:  142 (71.00%)\n  Ratio (Pos:Neg): 1:2.45\n\nA (AMD):\n  Positive:   44 (22.00%)\n  Negative:  156 (78.00%)\n  Ratio (Pos:Neg): 1:3.55\n\n======================================================================\nOffsite Test Set Statistics\n======================================================================\nTotal images: 200\n\nD (DR):\n  Positive:  140 (70.00%)\n  Negative:   60 (30.00%)\n  Ratio (Pos:Neg): 1:0.43\n\nG (Glaucoma):\n  Positive:   49 (24.50%)\n  Negative:  151 (75.50%)\n  Ratio (Pos:Neg): 1:3.08\n\nA (AMD):\n  Positive:   22 (11.00%)\n  Negative:  178 (89.00%)\n  Ratio (Pos:Neg): 1:8.09\n\n======================================================================\nCLASS WEIGHTS (for weighted BCE loss)\n======================================================================\n  D (DR): 0.5474\n  G (Glaucoma): 3.9080\n  A (AMD): 4.6338\n======================================================================\n\n\n======================================================================\nAUGMENTATION STRATEGY\n======================================================================\nOriginal training images: 800\nWith augmentation (random transforms applied on-the-fly):\n  - Each epoch sees different augmented versions\n  - Effective dataset size: 800 Ã— augmentation variations\n  - Augmentation includes: rotation, flips, crops, color jitter,\n    affine transforms, shear, grayscale, elastic transforms\n======================================================================\n","output_type":"stream"}],"execution_count":4},{"id":"22958de2","cell_type":"code","source":"# Install albumentations if not already installed\ntry:\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\nexcept ImportError:\n    print(\"Installing albumentations...\")\n    import subprocess\n    subprocess.check_call([\"pip\", \"install\", \"-q\", \"albumentations\"])\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n\nclass RetinaMultiLabelDataset(Dataset):\n    def __init__(self, csv_file, image_dir, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        img_path = os.path.join(self.image_dir, row.iloc[0])\n        # Load as numpy array for Albumentations\n        img = np.array(Image.open(img_path).convert(\"RGB\"))\n        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n        \n        if self.transform:\n            transformed = self.transform(image=img)\n            img = transformed['image']\n        \n        return img, labels, row.iloc[0]  # Also return filename for submission\n\n\n# LIGHT AUGMENTATION with Albumentations (reduces overfitting)\ntrain_transform_light = A.Compose([\n    A.Resize(224, 224),\n    A.HorizontalFlip(p=0.5),\n    A.Affine(translate_percent=0.1, scale=(0.9, 1.1), rotate=5),\n    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\n# Inception V3 needs 299x299\ntrain_transform_inception = A.Compose([\n    A.Resize(299, 299),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.3),\n    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\n# Validation/Test transform (no augmentation)\nval_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\nval_transform_inception = A.Compose([\n    A.Resize(299, 299),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\nprint(\"âœ… Albumentations transforms configured (LIGHT augmentation to reduce overfitting):\")\nprint(\"  â€¢ train_transform_light: Minimal augmentation (224x224)\")\nprint(\"    - HorizontalFlip, ShiftScaleRotate (slight), RandomBrightnessContrast (subtle)\")\nprint(\"  â€¢ train_transform_inception: Same but 299x299 for Inception V3\")\nprint(\"  â€¢ val_transform: No augmentation (224x224)\")\nprint(\"  â€¢ val_transform_inception: No augmentation (299x299)\")\nprint(\"  â€¢ âš ï¸ Reduced augmentation strength to combat overfitting!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T06:44:27.173134Z","iopub.execute_input":"2025-12-31T06:44:27.173817Z","iopub.status.idle":"2025-12-31T06:44:27.191495Z","shell.execute_reply.started":"2025-12-31T06:44:27.173786Z","shell.execute_reply":"2025-12-31T06:44:27.190709Z"}},"outputs":[{"name":"stdout","text":"âœ… Albumentations transforms configured (LIGHT augmentation to reduce overfitting):\n  â€¢ train_transform_light: Minimal augmentation (224x224)\n    - HorizontalFlip, ShiftScaleRotate (slight), RandomBrightnessContrast (subtle)\n  â€¢ train_transform_inception: Same but 299x299 for Inception V3\n  â€¢ val_transform: No augmentation (224x224)\n  â€¢ val_transform_inception: No augmentation (299x299)\n  â€¢ âš ï¸ Reduced augmentation strength to combat overfitting!\n","output_type":"stream"}],"execution_count":47},{"id":"7292b431","cell_type":"code","source":"# ============================================================================\n# GRADCAM IMPLEMENTATION FOR EXPLAINABLE AI\n# ============================================================================\n\nclass GradCAM:\n    \"\"\"\n    GradCAM: Gradient-weighted Class Activation Mapping\n    Generates attention maps showing which features contribute most to model decisions\n    \"\"\"\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n        \n        # Register hooks\n        target_layer.register_forward_hook(self.save_activation)\n        target_layer.register_backward_hook(self.save_gradient)\n    \n    def save_activation(self, module, input, output):\n        self.activations = output.detach()\n    \n    def save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0].detach()\n    \n    def generate_cam(self, input_image, target_class=None):\n        \"\"\"Generate GradCAM heatmap for the input image\"\"\"\n        # Forward pass\n        model_output = self.model(input_image)\n        \n        if target_class is None:\n            # For multi-label, we'll use the mean of all predictions\n            target_class = torch.sigmoid(model_output).mean()\n        else:\n            target_class = model_output[:, target_class]\n        \n        # Backward pass\n        self.model.zero_grad()\n        target_class.backward(torch.ones_like(target_class), retain_graph=True)\n        \n        # Get gradients and activations\n        gradients = self.gradients  # [batch, channels, h, w]\n        activations = self.activations  # [batch, channels, h, w]\n        \n        # Global average pooling on gradients\n        weights = gradients.mean(dim=(2, 3), keepdim=True)  # [batch, channels, 1, 1]\n        \n        # Weighted combination of activation maps\n        cam = (weights * activations).sum(dim=1, keepdim=True)  # [batch, 1, h, w]\n        \n        # Apply ReLU to focus on positive contributions\n        cam = F.relu(cam)\n        \n        # Normalize\n        cam = cam - cam.min()\n        cam = cam / (cam.max() + 1e-8)\n        \n        return cam\n    \n    def visualize_cam(self, input_image, cam, original_image=None):\n        \"\"\"Overlay GradCAM heatmap on the original image\"\"\"\n        # Resize CAM to match input image size\n        cam_resized = F.interpolate(cam, size=input_image.shape[2:], mode='bilinear', align_corners=False)\n        cam_resized = cam_resized.squeeze().cpu().numpy()\n        \n        # Convert to heatmap\n        heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n        \n        if original_image is not None:\n            # Denormalize original image\n            mean = np.array([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n            std = np.array([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n            img = input_image.squeeze().cpu().numpy()\n            img = img * std + mean\n            img = np.transpose(img, (1, 2, 0))\n            img = np.clip(img, 0, 1)\n            img = np.uint8(255 * img)\n            \n            # Overlay\n            overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n            return overlay\n        \n        return heatmap\n\n\nclass GradCAMPlusPlus(GradCAM):\n    \"\"\"\n    Improved version of GradCAM with better localization\n    \"\"\"\n    def generate_cam(self, input_image, target_class=None):\n        \"\"\"Generate GradCAM++ heatmap\"\"\"\n        # Forward pass\n        model_output = self.model(input_image)\n        \n        if target_class is None:\n            target_class = torch.sigmoid(model_output).mean()\n        else:\n            target_class = model_output[:, target_class]\n        \n        # Backward pass\n        self.model.zero_grad()\n        target_class.backward(torch.ones_like(target_class), retain_graph=True)\n        \n        gradients = self.gradients\n        activations = self.activations\n        \n        # Calculate alpha weights (importance of each activation map)\n        grad_2 = gradients.pow(2)\n        grad_3 = grad_2 * gradients\n        \n        alpha = grad_2 / (2 * grad_2 + (grad_3 * activations).sum(dim=(2, 3), keepdim=True) + 1e-8)\n        \n        # Apply ReLU to positive gradients only\n        weights = (alpha * F.relu(gradients)).sum(dim=(2, 3), keepdim=True)\n        \n        # Weighted combination\n        cam = (weights * activations).sum(dim=1, keepdim=True)\n        cam = F.relu(cam)\n        \n        # Normalize\n        cam = cam - cam.min()\n        cam = cam / (cam.max() + 1e-8)\n        \n        return cam\n\n\ndef get_target_layer(model, backbone_name):\n    \"\"\"Get the appropriate layer for GradCAM based on backbone\"\"\"\n    # Handle DataParallel wrapper\n    if isinstance(model, nn.DataParallel):\n        model = model.module\n    \n    if 'resnet' in backbone_name.lower():\n        return model.backbone.layer4[-1]\n    elif 'densenet' in backbone_name.lower():\n        # For DenseNet, use the last dense block\n        return model.backbone.features.denseblock4.denselayer16.conv2\n    elif 'inception' in backbone_name.lower():\n        # For Inception-V3, use the last mixed layer\n        return model.backbone.Mixed_7c.branch_pool\n    elif 'shufflenet' in backbone_name.lower():\n        # For ShuffleNet V2, use the last convolutional layer\n        return model.backbone.conv5\n    elif 'vit' in backbone_name.lower():\n        # For ViT, use the last attention block\n        return model.backbone.blocks[-1].norm1\n    else:\n        # Default: try to find the last convolutional/norm layer\n        for name, module in reversed(list(model.named_modules())):\n            if isinstance(module, (nn.Conv2d, nn.LayerNorm, nn.BatchNorm2d)):\n                return module\n    \n    raise ValueError(f\"Could not find suitable target layer for {backbone_name}\")\n\n\nprint(\"âœ… GradCAM and GradCAM++ implementations added for explainable AI\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T06:44:32.132678Z","iopub.execute_input":"2025-12-31T06:44:32.133439Z","iopub.status.idle":"2025-12-31T06:44:32.151210Z","shell.execute_reply.started":"2025-12-31T06:44:32.133408Z","shell.execute_reply":"2025-12-31T06:44:32.150331Z"}},"outputs":[{"name":"stdout","text":"âœ… GradCAM and GradCAM++ implementations added for explainable AI\n","output_type":"stream"}],"execution_count":48},{"id":"4deb3ab4","cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport timm\nimport numpy as np\n\n\n# ============================================================================\n# SE BLOCK (KEEP AS IS)\n# ============================================================================\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(SEBlock, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n\n# ============================================================================\n# MINIMAL CLASSIFIER - THIS IS KEY!\n# ============================================================================\n\nclass OptimalMultiLabelClassifier(nn.Module):\n    \"\"\"\n    ULTRA-SIMPLIFIED classifier for better performance\n    Key: For only 3 classes, we don't need complex heads!\n    \"\"\"\n    def __init__(self, backbone_name, num_classes=3, dropout=0.3, pretrained=True, use_se=True):\n        super(OptimalMultiLabelClassifier, self).__init__()\n        self.backbone_name = backbone_name\n        self.use_se = use_se\n        \n        # ================================================================\n        # BACKBONE\n        # ================================================================\n        if backbone_name == 'resnet50':\n            self.backbone = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)\n            num_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            \n            if use_se:\n                original_layer4 = self.backbone.layer4\n                self.backbone.layer4 = nn.Sequential(\n                    original_layer4,\n                    SEBlock(num_features, reduction=16)\n                )\n            \n        elif backbone_name == 'densenet121':\n            self.backbone = models.densenet121(weights='IMAGENET1K_V1' if pretrained else None)\n            num_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            \n            if use_se:\n                self.se_block_post = SEBlock(num_features, reduction=16)\n            \n        elif backbone_name == 'inception_v3':\n            self.backbone = models.inception_v3(weights='IMAGENET1K_V1' if pretrained else None, aux_logits=False)\n            num_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            \n            if use_se:\n                self.se_block_post = SEBlock(num_features, reduction=16)\n            \n        elif backbone_name == 'shufflenet_v2':\n            self.backbone = models.shufflenet_v2_x1_0(weights='IMAGENET1K_V1' if pretrained else None)\n            num_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            \n            if use_se:\n                self.se_block_post = SEBlock(num_features, reduction=16)\n            \n        elif backbone_name == 'vit_base_patch16_224':\n            self.backbone = timm.create_model('vit_base_patch16_224', pretrained=pretrained, num_classes=0)\n            num_features = self.backbone.num_features\n            \n        else:\n            raise ValueError(f\"Unknown backbone: {backbone_name}\")\n        \n        self.adaptive_pool = nn.AdaptiveAvgPool2d(1)\n        self.num_features = num_features\n        \n        # ================================================================\n        # ULTRA-SIMPLE CLASSIFIER (Just dropout + linear!)\n        # This is THE KEY to breaking 83%\n        # ================================================================\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(num_features, num_classes)\n        )\n        \n        # Initialize\n        nn.init.xavier_uniform_(self.classifier[1].weight)\n        nn.init.constant_(self.classifier[1].bias, 0)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        \n        if len(features.shape) == 4:\n            if self.use_se and hasattr(self, 'se_block_post'):\n                features = self.se_block_post(features)\n            features = self.adaptive_pool(features).flatten(1)\n        elif len(features.shape) == 3:\n            features = features.mean(dim=1)\n        \n        return self.classifier(features)\n    \n    def unfreeze_layers(self, num_layers=None):\n        if num_layers is None:\n            for param in self.backbone.parameters():\n                param.requires_grad = True\n        else:\n            all_params = list(self.backbone.parameters())\n            for param in all_params[-num_layers:]:\n                param.requires_grad = True\n    \n    def freeze_backbone(self):\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n    \n    def get_num_trainable_params(self):\n        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n\n\n# ============================================================================\n# FOCAL LOSS + LABEL SMOOTHING (Critical improvements!)\n# ============================================================================\n\nclass FocalLossWithLabelSmoothing(nn.Module):\n    \"\"\"\n    Combines Focal Loss (for hard examples) + Label Smoothing (for generalization)\n    This will push you past 83%!\n    \"\"\"\n    def __init__(self, alpha=0.25, gamma=2.0, smoothing=0.1, pos_weight=None):\n        super(FocalLossWithLabelSmoothing, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.smoothing = smoothing\n        self.pos_weight = pos_weight\n    \n    def forward(self, pred, target):\n        # Apply label smoothing\n        target = target * (1 - self.smoothing) + 0.5 * self.smoothing\n        \n        # Calculate BCE\n        bce_loss = F.binary_cross_entropy_with_logits(\n            pred, target, pos_weight=self.pos_weight, reduction='none'\n        )\n        \n        # Calculate focal weight\n        pred_prob = torch.sigmoid(pred)\n        p_t = target * pred_prob + (1 - target) * (1 - pred_prob)\n        focal_weight = (1 - p_t) ** self.gamma\n        \n        # Apply focal weight and alpha\n        loss = self.alpha * focal_weight * bce_loss\n        \n        return loss.mean()\n\n\n# ============================================================================\n# MIXUP (Keep as is but ensure it's used!)\n# ============================================================================\n\nclass MixUpLoss(nn.Module):\n    def __init__(self, base_criterion):\n        super(MixUpLoss, self).__init__()\n        self.base_criterion = base_criterion\n    \n    def forward(self, pred, target_a, target_b, lam):\n        return lam * self.base_criterion(pred, target_a) + \\\n               (1 - lam) * self.base_criterion(pred, target_b)\n\n\ndef mixup_data(x, y, alpha=0.2):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n    \n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n    \n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    \n    return mixed_x, y_a, y_b, lam\n\n\n# ============================================================================\n# COSINE ANNEALING WARMUP (Better than ReduceLROnPlateau!)\n# ============================================================================\n\nclass CosineAnnealingWarmupRestarts:\n    \"\"\"\n    Cosine annealing with warmup - better learning rate schedule\n    \"\"\"\n    def __init__(self, optimizer, first_cycle_steps, warmup_steps, max_lr, min_lr, gamma=0.9):\n        self.optimizer = optimizer\n        self.first_cycle_steps = first_cycle_steps\n        self.warmup_steps = warmup_steps\n        self.max_lr = max_lr\n        self.min_lr = min_lr\n        self.gamma = gamma\n        self.step_count = 0\n        self.cycle = 0\n        self.current_lr = max_lr\n    \n    def step(self):\n        self.step_count += 1\n        \n        if self.step_count < self.warmup_steps:\n            # Warmup\n            lr = self.max_lr * (self.step_count / self.warmup_steps)\n        else:\n            # Cosine annealing\n            progress = (self.step_count - self.warmup_steps) / (self.first_cycle_steps - self.warmup_steps)\n            lr = self.min_lr + (self.max_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))\n        \n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = lr\n        \n        self.current_lr = lr\n        \n        # Reset for next cycle\n        if self.step_count >= self.first_cycle_steps:\n            self.step_count = 0\n            self.max_lr *= self.gamma","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T08:12:48.565347Z","iopub.execute_input":"2025-12-31T08:12:48.565637Z","iopub.status.idle":"2025-12-31T08:12:48.589067Z","shell.execute_reply.started":"2025-12-31T08:12:48.565612Z","shell.execute_reply":"2025-12-31T08:12:48.588127Z"}},"outputs":[],"execution_count":78},{"id":"3ab23b95","cell_type":"code","source":"# ============================================================================\n# COMPLETE OPTIMIZED TRAINING & EVALUATION UTILITIES\n# ============================================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n\n\n# ============================================================================\n# ADVANCED LOSS FUNCTIONS\n# ============================================================================\n\nclass FocalLossWithLabelSmoothing(nn.Module):\n    \"\"\"\n    Focal Loss + Label Smoothing for better generalization\n    Focuses on hard examples while preventing overconfidence\n    \"\"\"\n    def __init__(self, alpha=0.25, gamma=2.0, smoothing=0.1, pos_weight=None):\n        super(FocalLossWithLabelSmoothing, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.smoothing = smoothing\n        self.pos_weight = pos_weight\n    \n    def forward(self, pred, target):\n        # Apply label smoothing: 1 â†’ 0.9, 0 â†’ 0.1 (with smoothing=0.1)\n        target_smooth = target * (1 - self.smoothing) + 0.5 * self.smoothing\n        \n        # BCE loss\n        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n            pred, target_smooth, pos_weight=self.pos_weight, reduction='none'\n        )\n        \n        # Focal weight: (1 - p_t)^gamma\n        pred_prob = torch.sigmoid(pred)\n        p_t = target_smooth * pred_prob + (1 - target_smooth) * (1 - pred_prob)\n        focal_weight = (1 - p_t) ** self.gamma\n        \n        # Apply focal weight and alpha\n        loss = self.alpha * focal_weight * bce_loss\n        \n        return loss.mean()\n\n\nclass MixUpLoss(nn.Module):\n    \"\"\"MixUp loss wrapper for any base criterion\"\"\"\n    def __init__(self, base_criterion):\n        super(MixUpLoss, self).__init__()\n        self.base_criterion = base_criterion\n    \n    def forward(self, pred, target_a, target_b, lam):\n        return lam * self.base_criterion(pred, target_a) + \\\n               (1 - lam) * self.base_criterion(pred, target_b)\n\n\ndef mixup_data(x, y, alpha=0.2):\n    \"\"\"\n    Apply MixUp augmentation\n    Args:\n        x: Input images [B, C, H, W]\n        y: Labels [B, num_classes]\n        alpha: Beta distribution parameter (higher = more mixing)\n    Returns:\n        mixed_x, y_a, y_b, lam\n    \"\"\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n    \n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n    \n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    \n    return mixed_x, y_a, y_b, lam\n\n\n# ============================================================================\n# METRICS CALCULATION\n# ============================================================================\n\ndef calculate_metrics(labels, predictions, threshold=0.5):\n    \"\"\"Calculate comprehensive metrics including F1 macro\"\"\"\n    predictions_binary = (predictions > threshold).astype(int)\n    \n    # Per-class metrics\n    accuracies = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n    \n    for i in range(labels.shape[1]):\n        acc = accuracy_score(labels[:, i], predictions_binary[:, i])\n        prec = precision_score(labels[:, i], predictions_binary[:, i], zero_division=0)\n        rec = recall_score(labels[:, i], predictions_binary[:, i], zero_division=0)\n        f1 = f1_score(labels[:, i], predictions_binary[:, i], zero_division=0)\n        \n        accuracies.append(acc)\n        precisions.append(prec)\n        recalls.append(rec)\n        f1_scores.append(f1)\n    \n    # Overall metrics\n    overall_accuracy = accuracy_score(labels.ravel(), predictions_binary.ravel())\n    f1_macro = f1_score(labels, predictions_binary, average='macro', zero_division=0)\n    f1_micro = f1_score(labels, predictions_binary, average='micro', zero_division=0)\n    \n    # Cohen's Kappa for each class\n    kappas = [cohen_kappa_score(labels[:, i], predictions_binary[:, i]) for i in range(labels.shape[1])]\n    \n    return {\n        'per_class_accuracy': accuracies,\n        'per_class_precision': precisions,\n        'per_class_recall': recalls,\n        'per_class_f1': f1_scores,\n        'per_class_kappa': kappas,\n        'overall_accuracy': overall_accuracy,\n        'f1_macro': f1_macro,\n        'f1_micro': f1_micro,\n        'mean_accuracy': np.mean(accuracies),\n        'mean_precision': np.mean(precisions),\n        'mean_recall': np.mean(recalls),\n        'mean_f1': np.mean(f1_scores),\n        'mean_kappa': np.mean(kappas)\n    }\n\n\n# ============================================================================\n# TRAINING FUNCTIONS\n# ============================================================================\n\ndef train_epoch(model, train_loader, criterion, mixup_criterion, optimizer, device, \n                use_mixup=True, mixup_alpha=0.2, mixup_prob=0.5, grad_clip=1.0):\n    \"\"\"\n    Train for one epoch with MixUp and gradient clipping\n    \"\"\"\n    model.train()\n    running_loss = 0.0\n    all_labels = []\n    all_predictions = []\n    \n    pbar = tqdm(train_loader, desc='Training', leave=False)\n    for images, labels, _ in pbar:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Apply MixUp with specified probability\n        if use_mixup and np.random.rand() > (1 - mixup_prob):\n            mixed_images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=mixup_alpha)\n            outputs = model(mixed_images)\n            loss = mixup_criterion(outputs, labels_a, labels_b, lam)\n            \n            # For metrics, use original labels\n            predictions = torch.sigmoid(outputs).detach().cpu().numpy()\n            all_labels.append(labels.cpu().numpy())\n            all_predictions.append(predictions)\n        else:\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            predictions = torch.sigmoid(outputs).detach().cpu().numpy()\n            all_labels.append(labels.cpu().numpy())\n            all_predictions.append(predictions)\n        \n        loss.backward()\n        \n        # Gradient clipping to prevent exploding gradients\n        if grad_clip > 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    all_labels = np.vstack(all_labels)\n    all_predictions = np.vstack(all_predictions)\n    metrics = calculate_metrics(all_labels, all_predictions)\n    \n    return running_loss / len(train_loader), metrics\n\n\ndef validate(model, val_loader, criterion, device):\n    \"\"\"Validate the model\"\"\"\n    model.eval()\n    running_loss = 0.0\n    all_labels = []\n    all_predictions = []\n    \n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Validation', leave=False)\n        for images, labels, _ in pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            \n            predictions = torch.sigmoid(outputs).cpu().numpy()\n            all_labels.append(labels.cpu().numpy())\n            all_predictions.append(predictions)\n            \n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    all_labels = np.vstack(all_labels)\n    all_predictions = np.vstack(all_predictions)\n    metrics = calculate_metrics(all_labels, all_predictions)\n    \n    return running_loss / len(val_loader), metrics\n\n\n# ============================================================================\n# EARLY STOPPING\n# ============================================================================\n\nclass EarlyStopping:\n    \"\"\"Early stopping with min_delta threshold\"\"\"\n    def __init__(self, patience=10, min_delta=0.0001, mode='max'):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.mode = mode\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        \n    def __call__(self, val_metric):\n        if self.best_score is None:\n            self.best_score = val_metric\n            return False\n        \n        if self.mode == 'max':\n            if val_metric > self.best_score + self.min_delta:\n                self.best_score = val_metric\n                self.counter = 0\n            else:\n                self.counter += 1\n        else:\n            if val_metric < self.best_score - self.min_delta:\n                self.best_score = val_metric\n                self.counter = 0\n            else:\n                self.counter += 1\n        \n        if self.counter >= self.patience:\n            self.early_stop = True\n        \n        return self.early_stop\n\n\n# ============================================================================\n# COMPLETE TRAINING PIPELINE\n# ============================================================================\n\ndef train_model(\n    model, \n    train_loader, \n    val_loader, \n    class_weights,\n    config,\n    device='cuda',\n    save_path=None\n):\n    \"\"\"\n    OPTIMIZED training pipeline with all improvements:\n    - Focal Loss + Label Smoothing\n    - MixUp augmentation\n    - Gradient clipping\n    - Cosine annealing or ReduceLROnPlateau\n    - Early stopping\n    - Two-stage fine-tuning\n    \"\"\"\n    \n    # Extract config\n    num_epochs = config.get('epochs', 1)\n    lr = config.get('lr', 1e-4)\n    weight_decay = config.get('weight_decay', 1e-3)\n    patience = config.get('patience', 15)\n    finetune_epoch = config.get('finetune_epoch', 25)\n    use_mixup = config.get('use_mixup', True)\n    mixup_alpha = config.get('mixup_alpha', 0.2)\n    mixup_prob = config.get('mixup_prob', 0.5)\n    grad_clip = config.get('grad_clip', 1.0)\n    use_focal_loss = config.get('use_focal_loss', True)\n    label_smoothing = config.get('label_smoothing', 0.1)\n    scheduler_type = config.get('scheduler', 'cosine')  # 'cosine' or 'plateau'\n    \n    # Setup loss functions\n    if use_focal_loss:\n        criterion = FocalLossWithLabelSmoothing(\n            alpha=config.get('focal_alpha', 0.25),\n            gamma=config.get('focal_gamma', 2.0),\n            smoothing=label_smoothing,\n            pos_weight=class_weights.to(device)\n        )\n        print(\"âœ… Using Focal Loss + Label Smoothing\")\n    else:\n        criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights.to(device))\n        print(\"âœ… Using BCE Loss\")\n    \n    mixup_criterion = MixUpLoss(criterion) if use_mixup else None\n    \n    # Setup optimizer\n    optimizer = optim.AdamW(\n        filter(lambda p: p.requires_grad, model.parameters()),\n        lr=lr,\n        weight_decay=weight_decay,\n        betas=(0.9, 0.999)\n    )\n    \n    # Setup scheduler\n    if scheduler_type == 'cosine':\n        scheduler = CosineAnnealingLR(\n            optimizer,\n            T_max=num_epochs,\n            eta_min=1e-7\n        )\n        print(\"âœ… Using Cosine Annealing LR\")\n    else:\n        scheduler = ReduceLROnPlateau(\n            optimizer,\n            mode='max',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-7\n        )\n        print(\"âœ… Using ReduceLROnPlateau\")\n    \n    # Early stopping\n    early_stopping = EarlyStopping(patience=patience, min_delta=0.0001, mode='max')\n    \n    # Tracking\n    history = {\n        'train_loss': [], 'val_loss': [],\n        'train_f1_macro': [], 'val_f1_macro': [],\n        'train_acc': [], 'val_acc': [],\n        'lr': []\n    }\n    \n    best_f1_macro = 0.0\n    best_model_state = None\n    finetuning_started = False\n    \n    # Print configuration\n    print(f\"\\n{'='*70}\")\n    print(f\"OPTIMIZED TRAINING CONFIGURATION\")\n    print(f\"{'='*70}\")\n    print(f\"Model: {config.get('name', 'Unknown')}\")\n    print(f\"Epochs: {num_epochs}\")\n    print(f\"Learning Rate: {lr}\")\n    print(f\"Weight Decay: {weight_decay} (STRONG!)\")\n    print(f\"Fine-tuning starts: Epoch {finetune_epoch}\")\n    print(f\"Early Stopping Patience: {patience}\")\n    print(f\"MixUp: {'Enabled' if use_mixup else 'Disabled'} (alpha={mixup_alpha}, prob={mixup_prob})\")\n    print(f\"Gradient Clipping: {grad_clip}\")\n    print(f\"Label Smoothing: {label_smoothing}\")\n    print(f\"Focal Loss: {'Enabled' if use_focal_loss else 'Disabled'}\")\n    print(f\"Scheduler: {scheduler_type}\")\n    print(f\"Class Weights: {class_weights.cpu().numpy()}\")\n    print(f\"{'='*70}\\n\")\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        # Start fine-tuning at specified epoch\n        if epoch == finetune_epoch and not finetuning_started:\n            print(f\"\\n{'ðŸ”¥'*35}\")\n            print(f\"ðŸš€ STARTING FINE-TUNING: Unfreezing backbone\")\n            print(f\"{'ðŸ”¥'*35}\\n\")\n            \n            # Unfreeze backbone\n            model_to_unfreeze = model.module if isinstance(model, nn.DataParallel) else model\n            model_to_unfreeze.unfreeze_layers()\n            \n            # Recreate optimizer with gentler LR reduction (divide by 3, not 10!)\n            lr_finetune = lr / 3\n            optimizer = optim.AdamW(\n                model.parameters(),\n                lr=lr_finetune,\n                weight_decay=weight_decay,\n                betas=(0.9, 0.999)\n            )\n            \n            # Reset scheduler\n            if scheduler_type == 'cosine':\n                scheduler = CosineAnnealingLR(\n                    optimizer,\n                    T_max=num_epochs - finetune_epoch,\n                    eta_min=1e-7\n                )\n            else:\n                scheduler = ReduceLROnPlateau(\n                    optimizer,\n                    mode='max',\n                    factor=0.5,\n                    patience=5,\n                    min_lr=1e-7\n                )\n            \n            finetuning_started = True\n        \n        # Epoch header\n        phase = '[FINE-TUNING]' if finetuning_started else '[TRANSFER LEARNING]'\n        print(f\"\\nEpoch {epoch+1}/{num_epochs} {phase}\")\n        print(\"-\" * 70)\n        \n        # Train\n        train_loss, train_metrics = train_epoch(\n            model, train_loader, criterion, mixup_criterion, optimizer, device,\n            use_mixup=use_mixup,\n            mixup_alpha=mixup_alpha,\n            mixup_prob=mixup_prob,\n            grad_clip=grad_clip\n        )\n        \n        # Validate\n        val_loss, val_metrics = validate(model, val_loader, criterion, device)\n        \n        # Update learning rate\n        current_lr = optimizer.param_groups[0]['lr']\n        if scheduler_type == 'cosine':\n            scheduler.step()\n        else:\n            scheduler.step(val_metrics['f1_macro'])\n        \n        # Store history\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['train_f1_macro'].append(train_metrics['f1_macro'])\n        history['val_f1_macro'].append(val_metrics['f1_macro'])\n        history['train_acc'].append(train_metrics['mean_accuracy'])\n        history['val_acc'].append(val_metrics['mean_accuracy'])\n        history['lr'].append(current_lr)\n        \n        # Print metrics\n        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n        print(f\"Train F1: {train_metrics['f1_macro']:.4f} | Val F1: {val_metrics['f1_macro']:.4f}\")\n        print(f\"Train Acc: {train_metrics['mean_accuracy']:.4f} | Val Acc: {val_metrics['mean_accuracy']:.4f}\")\n        print(f\"Learning Rate: {current_lr:.6f}\")\n        print(f\"Train-Val F1 Gap: {abs(train_metrics['f1_macro'] - val_metrics['f1_macro']):.4f}\")\n        \n        # Save best model\n        if val_metrics['f1_macro'] > best_f1_macro:\n            best_f1_macro = val_metrics['f1_macro']\n            best_model_state = model.state_dict().copy()\n            print(f\"âœ… New best Val F1: {best_f1_macro:.4f}\")\n            \n            if save_path:\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': best_model_state,\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'best_f1_macro': best_f1_macro,\n                    'val_metrics': val_metrics,\n                    'config': config\n                }, save_path)\n                print(f\"âœ… Model saved to {save_path}\")\n        \n        # Early stopping\n        if early_stopping(val_metrics['f1_macro']):\n            print(f\"\\nâš ï¸ Early stopping at epoch {epoch+1}\")\n            print(f\"Best Val F1: {best_f1_macro:.4f}\")\n            break\n    \n    # Load best model\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        print(f\"\\nâœ… Loaded best model (Val F1: {best_f1_macro:.4f})\")\n    \n    return model, history\n\n\n# ============================================================================\n# SUMMARY\n# ============================================================================\n\nprint(\"=\" * 70)\nprint(\"âœ… OPTIMIZED TRAINING UTILITIES LOADED\")\nprint(\"=\" * 70)\nprint(\"\\nðŸš€ KEY FEATURES:\")\nprint(\"  â€¢ Focal Loss + Label Smoothing (better generalization)\")\nprint(\"  â€¢ MixUp augmentation (configurable probability)\")\nprint(\"  â€¢ Gradient clipping (prevents instability)\")\nprint(\"  â€¢ Cosine Annealing or ReduceLROnPlateau\")\nprint(\"  â€¢ Two-stage fine-tuning (gentle LR reduction)\")\nprint(\"  â€¢ Tighter early stopping\")\nprint(\"  â€¢ Comprehensive metrics tracking\")\n\nprint(\"\\nðŸ’¡ USAGE:\")\nprint(\"\"\"\n# Train with optimal settings\nmodel, history = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    class_weights=class_weights,\n    config=OPTIMAL_CONFIGS['vit_base_optimal'],\n    device='cuda',\n    save_path='best_model.pth'\n)\n\"\"\")\nprint(\"=\" * 70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T08:12:51.474437Z","iopub.execute_input":"2025-12-31T08:12:51.474942Z","iopub.status.idle":"2025-12-31T08:12:51.513876Z","shell.execute_reply.started":"2025-12-31T08:12:51.474911Z","shell.execute_reply":"2025-12-31T08:12:51.513120Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nâœ… OPTIMIZED TRAINING UTILITIES LOADED\n======================================================================\n\nðŸš€ KEY FEATURES:\n  â€¢ Focal Loss + Label Smoothing (better generalization)\n  â€¢ MixUp augmentation (configurable probability)\n  â€¢ Gradient clipping (prevents instability)\n  â€¢ Cosine Annealing or ReduceLROnPlateau\n  â€¢ Two-stage fine-tuning (gentle LR reduction)\n  â€¢ Tighter early stopping\n  â€¢ Comprehensive metrics tracking\n\nðŸ’¡ USAGE:\n\n# Train with optimal settings\nmodel, history = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    class_weights=class_weights,\n    config=OPTIMAL_CONFIGS['vit_base_optimal'],\n    device='cuda',\n    save_path='best_model.pth'\n)\n\n======================================================================\n","output_type":"stream"}],"execution_count":79},{"id":"fb1a50c9","cell_type":"code","source":"# ============================================================================\n# PREDICTION & SUBMISSION GENERATION\n# ============================================================================\n\ndef generate_predictions(model, test_loader, device):\n    \"\"\"Generate predictions for test set\"\"\"\n    model.eval()\n    all_predictions = []\n    all_filenames = []\n    \n    with torch.no_grad():\n        pbar = tqdm(test_loader, desc='Generating predictions')\n        for images, labels, filenames in pbar:\n            images = images.to(device)\n            outputs = model(images)\n            predictions = torch.sigmoid(outputs).cpu().numpy()\n            \n            all_predictions.append(predictions)\n            all_filenames.extend(filenames)\n    \n    predictions = np.vstack(all_predictions)\n    predictions_binary = (predictions > 0.5).astype(int)\n    \n    return all_filenames, predictions_binary\n\n\ndef create_submission(filenames, predictions, output_path):\n    \"\"\"Create submission CSV file\"\"\"\n    submission_df = pd.DataFrame({\n        'id': filenames,\n        'D': predictions[:, 0],\n        'G': predictions[:, 1],\n        'A': predictions[:, 2]\n    })\n    submission_df.to_csv(output_path, index=False)\n    print(f\"âœ… Submission saved to {output_path}\")\n    return submission_df\n\n\ndef visualize_gradcam_samples(model, dataset, num_samples=5, save_dir=None):\n    \"\"\"Visualize GradCAM for sample images\"\"\"\n    model.eval()\n    \n    # Get target layer\n    target_layer = get_target_layer(model, model.backbone_name)\n    gradcam = GradCAMPlusPlus(model, target_layer)\n    \n    # Create directory if needed\n    if save_dir:\n        os.makedirs(save_dir, exist_ok=True)\n    \n    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples * 4))\n    if num_samples == 1:\n        axes = axes.reshape(1, -1)\n    \n    disease_names = ['DR (Diabetic Retinopathy)', 'Glaucoma', 'AMD']\n    \n    for i in range(num_samples):\n        img, label, filename = dataset[i]\n        img_batch = img.unsqueeze(0).to(device)\n        \n        # Original image\n        mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n        std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n        img_denorm = img * std + mean\n        img_denorm = torch.clamp(img_denorm, 0, 1)\n        img_np = img_denorm.permute(1, 2, 0).numpy()\n        \n        axes[i, 0].imshow(img_np)\n        axes[i, 0].set_title(f'{filename}\\nLabels: {label.numpy()}')\n        axes[i, 0].axis('off')\n        \n        # GradCAM for each disease\n        for disease_idx in range(3):\n            cam = gradcam.generate_cam(img_batch, target_class=disease_idx)\n            cam_vis = gradcam.visualize_cam(img_batch, cam)\n            \n            axes[i, disease_idx + 1].imshow(cam_vis)\n            axes[i, disease_idx + 1].set_title(f'{disease_names[disease_idx]}')\n            axes[i, disease_idx + 1].axis('off')\n    \n    plt.tight_layout()\n    if save_dir:\n        plt.savefig(os.path.join(save_dir, 'gradcam_visualization.png'), dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"âœ… GradCAM visualization complete\")\n\n\nprint(\"âœ… Prediction and visualization utilities ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T08:12:56.565518Z","iopub.execute_input":"2025-12-31T08:12:56.565811Z","iopub.status.idle":"2025-12-31T08:12:56.578808Z","shell.execute_reply.started":"2025-12-31T08:12:56.565785Z","shell.execute_reply":"2025-12-31T08:12:56.578097Z"}},"outputs":[{"name":"stdout","text":"âœ… Prediction and visualization utilities ready\n","output_type":"stream"}],"execution_count":80},{"id":"01c5dde2","cell_type":"code","source":"# ============================================================================\n# EXPERIMENT CONFIGURATION\n# ============================================================================\n\nOPTIMAL_EXPERIMENTS = [\n    {\n        'name': 'vit_base_optimal',\n        'backbone': 'vit_base_patch16_224',\n        'dropout': 0.5,              \n        'lr': 8e-7,                  \n        'weight_decay': 5e-3,      \n        'epochs': 1,               \n        'patience': 12,            \n        'batch_size': 20,          \n        'finetune_epoch': 1,      \n        'use_se': True,\n        'use_mixup': True,\n        'mixup_alpha': 0.4,         \n        'mixup_prob': 0.6,          \n        'use_focal_loss': True,\n        'focal_alpha': 0.25,\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.15,    \n        'grad_clip': 1.0,\n        'scheduler': 'cosine',     \n    },\n    {\n        'name': 'resnet50_optimal',\n        'backbone': 'resnet50',\n        'dropout': 0.4,          \n        'lr': 1e-7,\n        'weight_decay': 1e-3,\n        'epochs': 1,\n        'patience': 15,\n        'batch_size': 32,\n        'finetune_epoch': 1,       \n        'use_se': True,\n        'use_mixup': True,\n        'mixup_alpha': 0.2,\n        'mixup_prob': 0.5,\n        'use_focal_loss': True,\n        'focal_alpha': 0.25,\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.1,\n        'grad_clip': 1.0,\n        'scheduler': 'cosine',\n    },\n    {\n        'name': 'densenet121_optimal',\n        'backbone': 'densenet121',\n        'dropout': 0.4,\n        'lr': 1e-7,\n        'weight_decay': 1e-3,\n        'epochs': 1,\n        'patience': 15,\n        'batch_size': 32,\n        'finetune_epoch': 1,\n        'use_se': True,\n        'use_mixup': True,\n        'mixup_alpha': 0.2,\n        'mixup_prob': 0.5,\n        'use_focal_loss': True,\n        'focal_alpha': 0.25,\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.1,\n        'grad_clip': 1.0,\n        'scheduler': 'cosine',\n    },\n    # {\n    #     'name': 'inception_v3_optimal',\n    #     'backbone': 'inception_v3',\n    #     'dropout': 0.3,\n    #     'lr': 1e-7,\n    #     'weight_decay': 1e-3,\n    #     'epochs': 1,\n    #     'patience': 15,\n    #     'batch_size': 24,\n    #     'finetune_epoch': 1,\n    #     'use_se': True,\n    #     'use_mixup': True,\n    #     'mixup_alpha': 0.2,\n    #     'mixup_prob': 0.5,\n    #     'use_focal_loss': True,\n    #     'focal_alpha': 0.25,\n    #     'focal_gamma': 2.0,\n    #     'label_smoothing': 0.1,\n    #     'grad_clip': 1.0,\n    #     'scheduler': 'cosine',\n    #     'input_size': 299,        \n    {\n        'name': 'shufflenet_v2_optimal',\n        'backbone': 'shufflenet_v2',\n        'dropout': 0.2,\n        'lr': 1e-4,\n        'weight_decay': 5e-4,       \n        'epochs': 1,\n        'patience': 20,\n        'batch_size': 48,\n        'finetune_epoch': 1,      \n        'use_se': True,\n        'use_mixup': True,\n        'mixup_alpha': 0.2,\n        'mixup_prob': 0.5,\n        'use_focal_loss': True,\n        'focal_alpha': 0.25,\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.1,\n        'grad_clip': 1.0,\n        'scheduler': 'cosine',\n    },\n]\n\n\n\n# Use Kaggle output directory\noutput_dir = \"/kaggle/working/task_4_3_experiment_results__final__\"\nos.makedirs(output_dir, exist_ok=True)\n\nprint(f\"âœ… Configured {len(experiments)} experiments with advanced fine-tuning\")\nprint(f\"âœ… Output directory: {output_dir}\")\n\nif use_multi_gpu and torch.cuda.device_count() > 1:\n    num_gpus = torch.cuda.device_count()\n    print(f\"\\nðŸ’¡ Multi-GPU training enabled: {num_gpus} GPUs\")\n\nprint(\"\\nðŸ“‹ Experiments to run:\")\nfor i, exp in enumerate(experiments, 1):\n    print(f\"  {i}. {exp['name']} - Fine-tuning after epoch {exp['finetune_epoch']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T09:06:54.271661Z","iopub.execute_input":"2025-12-31T09:06:54.271985Z","iopub.status.idle":"2025-12-31T09:06:54.283601Z","shell.execute_reply.started":"2025-12-31T09:06:54.271956Z","shell.execute_reply":"2025-12-31T09:06:54.282818Z"}},"outputs":[{"name":"stdout","text":"âœ… Configured 5 experiments with advanced fine-tuning\nâœ… Output directory: /kaggle/working/task_4_3_experiment_results__final__\n\nðŸ“‹ Experiments to run:\n  1. vit_base_v6 - Fine-tuning after epoch 25\n  2. resnet50_v6 - Fine-tuning after epoch 25\n  3. densenet121_finetuned_v6 - Fine-tuning after epoch 25\n  4. inception_v3_finetuned_v6 - Fine-tuning after epoch 10\n  5. shufflenet_v2_finetuned_v6 - Fine-tuning after epoch 30\n","output_type":"stream"}],"execution_count":90},{"id":"ec3985ed","cell_type":"code","source":"\ndef run_experiment(config, exp_num, total_experiments, train_csv, val_csv, \n                   offsite_test_csv, onsite_test_img_dir,\n                   train_img_dir, val_img_dir, offsite_test_img_dir,\n                   train_transform, val_transform, class_weights, device, output_dir):\n    \"\"\"\n    Run a single experiment with optimized configuration\n    \"\"\"\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"EXPERIMENT {exp_num}/{total_experiments}: {config['name']}\")\n    print(f\"{'='*80}\")\n    print(f\"Backbone: {config['backbone']}\")\n    print(f\"Dropout: {config['dropout']}\")\n    print(f\"Learning Rate: {config['lr']}\")\n    print(f\"Weight Decay: {config['weight_decay']}\")\n    print(f\"Batch Size: {config['batch_size']}\")\n    print(f\"Fine-tuning: Epoch {config['finetune_epoch']}\")\n    print(f\"MixUp: {'Yes' if config.get('use_mixup', False) else 'No'} (alpha={config.get('mixup_alpha', 0.2)})\")\n    print(f\"Focal Loss: {'Yes' if config.get('use_focal_loss', False) else 'No'}\")\n    print(f\"Label Smoothing: {config.get('label_smoothing', 0.0)}\")\n    print(f\"Scheduler: {config.get('scheduler', 'plateau')}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Check if Inception needs different transform\n    input_size = config.get('input_size', 224)\n    if input_size == 299:\n        print(f\"âš ï¸  Using 299x299 images for Inception V3\")\n        # You'll need to create inception-specific transforms\n        # For now, warning only\n    \n    # Create datasets\n    train_dataset = RetinaMultiLabelDataset(train_csv, train_img_dir, transform=train_transform)\n    val_dataset = RetinaMultiLabelDataset(val_csv, val_img_dir, transform=val_transform)\n    offsite_test_dataset = RetinaMultiLabelDataset(offsite_test_csv, offsite_test_img_dir, transform=val_transform)\n    \n    # For onsite test (no labels in CSV)\n    onsite_test_files = sorted([f for f in os.listdir(onsite_test_img_dir) if f.endswith(('.jpg', '.png'))])\n    onsite_test_data = pd.DataFrame({\n        'id': onsite_test_files,\n        'D': [0] * len(onsite_test_files),\n        'G': [0] * len(onsite_test_files),\n        'A': [0] * len(onsite_test_files)\n    })\n    onsite_test_csv_temp = os.path.join(output_dir, f'temp_onsite_{config[\"name\"]}.csv')\n    onsite_test_data.to_csv(onsite_test_csv_temp, index=False)\n    onsite_test_dataset = RetinaMultiLabelDataset(onsite_test_csv_temp, onsite_test_img_dir, transform=val_transform)\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=config['batch_size'], \n        shuffle=True, \n        num_workers=0,\n        pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=config['batch_size'], \n        shuffle=False, \n        num_workers=0,\n        pin_memory=True\n    )\n    offsite_test_loader = DataLoader(\n        offsite_test_dataset, \n        batch_size=config['batch_size'], \n        shuffle=False, \n        num_workers=0\n    )\n    onsite_test_loader = DataLoader(\n        onsite_test_dataset, \n        batch_size=config['batch_size'], \n        shuffle=False, \n        num_workers=0\n    )\n    \n    print(f\"Dataset sizes:\")\n    print(f\"  Train: {len(train_dataset)}\")\n    print(f\"  Validation: {len(val_dataset)}\")\n    print(f\"  Offsite Test: {len(offsite_test_dataset)}\")\n    print(f\"  Onsite Test: {len(onsite_test_dataset)}\\n\")\n    \n    # Create model with optimal settings\n    model = create_model(\n        backbone_name=config['backbone'],\n        num_classes=3,\n        dropout=config['dropout'],\n        use_se=config.get('use_se', True),\n        device=device,\n        multi_gpu=torch.cuda.device_count() > 1\n    )\n    \n    # Count parameters\n    if isinstance(model, nn.DataParallel):\n        total_params = sum(p.numel() for p in model.module.parameters())\n        trainable_params = sum(p.numel() for p in model.module.parameters() if p.requires_grad)\n    else:\n        total_params = sum(p.numel() for p in model.parameters())\n        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"Model parameters:\")\n    print(f\"  Total: {total_params:,}\")\n    print(f\"  Trainable (initial): {trainable_params:,}\\n\")\n    \n    # Define model save path\n    model_path = os.path.join(output_dir, f'{config[\"name\"]}_best.pth')\n    \n    # Train model with all optimizations\n    try:\n        trained_model, history = train_model(\n            model=model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            class_weights=class_weights,\n            config=config,\n            device=device,\n            save_path=model_path\n        )\n    except Exception as e:\n        print(f\"\\nâŒ Training failed for {config['name']}: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n    \n    # Load best model for inference\n    print(f\"\\n{'='*70}\")\n    print(\"Loading best model for inference...\")\n    print(f\"{'='*70}\")\n    checkpoint = torch.load(model_path, weights_only=False)\n    if isinstance(trained_model, nn.DataParallel):\n        trained_model.module.load_state_dict(checkpoint['model_state_dict'])\n    else:\n        trained_model.load_state_dict(checkpoint['model_state_dict'])\n    \n    # Generate predictions for offsite test\n    print(f\"\\n{'='*70}\")\n    print(\"Generating Offsite Test Predictions\")\n    print(f\"{'='*70}\")\n    offsite_filenames, offsite_predictions = generate_predictions(trained_model, offsite_test_loader, device)\n    offsite_submission_path = os.path.join(output_dir, f'{config[\"name\"]}_offsite_submission.csv')\n    create_submission(offsite_filenames, offsite_predictions, offsite_submission_path)\n    \n    # Generate predictions for onsite test\n    print(f\"\\n{'='*70}\")\n    print(\"Generating Onsite Test Predictions\")\n    print(f\"{'='*70}\")\n    onsite_filenames, onsite_predictions = generate_predictions(trained_model, onsite_test_loader, device)\n    onsite_submission_path = os.path.join(output_dir, f'{config[\"name\"]}_onsite_submission.csv')\n    create_submission(onsite_filenames, onsite_predictions, onsite_submission_path)\n    \n    # Visualize GradCAM (optional)\n    print(f\"\\n{'='*70}\")\n    print(\"Generating GradCAM Visualizations\")\n    print(f\"{'='*70}\")\n    gradcam_dir = os.path.join(output_dir, f'{config[\"name\"]}_gradcam')\n    try:\n        visualize_gradcam_samples(trained_model, val_dataset, num_samples=5, save_dir=gradcam_dir)\n    except Exception as e:\n        print(f\"âš ï¸ GradCAM visualization skipped: {e}\")\n    \n    # Plot training history\n    print(f\"\\n{'='*70}\")\n    print(\"Plotting Training History\")\n    print(f\"{'='*70}\")\n    \n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    fig.suptitle(f'{config[\"name\"]} Training History', fontsize=16, fontweight='bold')\n    \n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    # Loss\n    axes[0, 0].plot(epochs, history['train_loss'], label='Train Loss', linewidth=2)\n    axes[0, 0].plot(epochs, history['val_loss'], label='Val Loss', linewidth=2)\n    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n    axes[0, 0].set_ylabel('Loss', fontsize=12)\n    axes[0, 0].set_title('Training and Validation Loss', fontsize=14)\n    axes[0, 0].legend(fontsize=11)\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    # F1 Macro\n    axes[0, 1].plot(epochs, history['train_f1_macro'], label='Train F1 Macro', linewidth=2)\n    axes[0, 1].plot(epochs, history['val_f1_macro'], label='Val F1 Macro', linewidth=2)\n    best_f1_idx = np.argmax(history['val_f1_macro'])\n    axes[0, 1].axvline(x=best_f1_idx+1, color='red', linestyle='--', alpha=0.5, label=f'Best (epoch {best_f1_idx+1})')\n    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n    axes[0, 1].set_ylabel('F1 Macro', fontsize=12)\n    axes[0, 1].set_title('F1 Macro Score', fontsize=14)\n    axes[0, 1].legend(fontsize=11)\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    # Accuracy\n    axes[1, 0].plot(epochs, history['train_acc'], label='Train Accuracy', linewidth=2)\n    axes[1, 0].plot(epochs, history['val_acc'], label='Val Accuracy', linewidth=2)\n    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n    axes[1, 0].set_ylabel('Accuracy', fontsize=12)\n    axes[1, 0].set_title('Mean Accuracy', fontsize=14)\n    axes[1, 0].legend(fontsize=11)\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    # Learning Rate\n    axes[1, 1].plot(epochs, history['lr'], linewidth=2, color='green')\n    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n    axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n    axes[1, 1].set_title('Learning Rate Schedule', fontsize=14)\n    axes[1, 1].set_yscale('log')\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    history_plot_path = os.path.join(output_dir, f'{config[\"name\"]}_history.png')\n    plt.savefig(history_plot_path, dpi=150, bbox_inches='tight')\n    plt.show()\n    plt.close()\n    \n    # Clean up temporary file\n    if os.path.exists(onsite_test_csv_temp):\n        os.remove(onsite_test_csv_temp)\n    \n    # Save training history\n    history_df = pd.DataFrame(history)\n    history_csv_path = os.path.join(output_dir, f'{config[\"name\"]}_history.csv')\n    history_df.to_csv(history_csv_path, index=False)\n    \n    # Calculate metrics\n    best_val_f1 = max(history['val_f1_macro'])\n    best_epoch = np.argmax(history['val_f1_macro']) + 1\n    final_train_f1 = history['train_f1_macro'][-1]\n    final_val_f1 = history['val_f1_macro'][-1]\n    train_val_gap = abs(final_train_f1 - final_val_f1)\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"âœ… EXPERIMENT {config['name']} COMPLETED\")\n    print(f\"{'='*70}\")\n    print(f\"Best Val F1 Macro: {best_val_f1:.4f} (Epoch {best_epoch})\")\n    print(f\"Final Train F1: {final_train_f1:.4f}\")\n    print(f\"Final Val F1: {final_val_f1:.4f}\")\n    print(f\"Train-Val Gap: {train_val_gap:.4f}\")\n    print(f\"\\nSaved files:\")\n    print(f\"  â€¢ Model: {model_path}\")\n    print(f\"  â€¢ Offsite submission: {offsite_submission_path}\")\n    print(f\"  â€¢ Onsite submission: {onsite_submission_path}\")\n    print(f\"  â€¢ Training history: {history_csv_path}\")\n    print(f\"  â€¢ History plot: {history_plot_path}\")\n    print(f\"{'='*70}\\n\")\n    \n    return {\n        'name': config['name'],\n        'best_val_f1_macro': best_val_f1,\n        'best_epoch': best_epoch,\n        'best_val_acc': max(history['val_acc']),\n        'final_train_f1_macro': final_train_f1,\n        'final_val_f1_macro': final_val_f1,\n        'train_val_gap': train_val_gap,\n        'total_epochs': len(history['train_loss']),\n        'model_path': model_path,\n        'offsite_submission': offsite_submission_path,\n        'onsite_submission': onsite_submission_path\n    }\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T09:06:59.899559Z","iopub.execute_input":"2025-12-31T09:06:59.899864Z","iopub.status.idle":"2025-12-31T09:06:59.928367Z","shell.execute_reply.started":"2025-12-31T09:06:59.899838Z","shell.execute_reply":"2025-12-31T09:06:59.927532Z"}},"outputs":[],"execution_count":92},{"id":"89e55333","cell_type":"code","source":"# ============================================================================\n# EXECUTE ALL EXPERIMENTS - UPDATED VERSION\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"STARTING ALL EXPERIMENTS\")\nprint(f\"{'#'*80}\\n\")\n\n# Verify all required variables exist\nrequired_vars = {\n    'train_csv': train_csv,\n    'val_csv': val_csv,\n    'offsite_test_csv': offsite_test_csv,\n    'onsite_test_img_dir': onsite_test_img_dir,\n    'train_img_dir': train_img_dir,\n    'val_img_dir': val_img_dir,\n    'offsite_test_img_dir': offsite_test_img_dir,\n    'train_transform': train_transform,\n    'val_transform': val_transform,\n    'class_weights': class_weights,\n    'device': device,\n    'output_dir': output_dir,\n}\n\nprint(\"Verifying required variables...\")\nfor var_name, var_value in required_vars.items():\n    if var_value is None:\n        print(f\"âŒ ERROR: {var_name} is not defined!\")\n    else:\n        print(f\"âœ… {var_name}: OK\")\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Running {len(experiments)} experiments\")\nprint(f\"Output directory: {output_dir}\")\nprint(f\"{'='*80}\\n\")\n\n# Track all results\nall_results = []\nfailed_experiments = []\n\n# Run each experiment\nfor i, config in enumerate(experiments, 1):\n    print(f\"\\n{'#'*80}\")\n    print(f\"STARTING EXPERIMENT {i}/{len(experiments)}: {config['name']}\")\n    print(f\"{'#'*80}\")\n    \n    try:\n        result = run_experiment(\n            config=config,\n            exp_num=i,\n            total_experiments=len(experiments),\n            train_csv=train_csv,\n            val_csv=val_csv,\n            offsite_test_csv=offsite_test_csv,\n            onsite_test_img_dir=onsite_test_img_dir,\n            train_img_dir=train_img_dir,\n            val_img_dir=val_img_dir,\n            offsite_test_img_dir=offsite_test_img_dir,\n            train_transform=train_transform,\n            val_transform=val_transform,\n            class_weights=class_weights,\n            device=device,\n            output_dir=output_dir\n        )\n        \n        if result is not None:\n            all_results.append(result)\n            print(f\"\\nâœ… Experiment {i}/{len(experiments)} completed successfully!\")\n        else:\n            failed_experiments.append(config['name'])\n            print(f\"\\nâš ï¸ Experiment {i}/{len(experiments)} returned None\")\n            \n    except KeyboardInterrupt:\n        print(f\"\\n\\nâš ï¸ Training interrupted by user!\")\n        print(f\"Completed {len(all_results)}/{len(experiments)} experiments\")\n        break\n        \n    except Exception as e:\n        failed_experiments.append(config['name'])\n        print(f\"\\nâŒ Experiment {config['name']} failed with error:\")\n        print(f\"   {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        print(f\"\\nContinuing with next experiment...\\n\")\n        continue\n    \n    finally:\n        # Memory cleanup after each experiment\n        import gc\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        # Progress update\n        print(f\"\\n{'='*80}\")\n        print(f\"PROGRESS: {len(all_results)} successful, {len(failed_experiments)} failed, {len(experiments) - i} remaining\")\n        print(f\"{'='*80}\\n\")\n\n\n# ============================================================================\n# FINAL SUMMARY\n# ============================================================================\n\nprint(f\"\\n{'#'*80}\")\nprint(\"ALL EXPERIMENTS COMPLETED!\")\nprint(f\"{'#'*80}\\n\")\n\nprint(f\"Results: {len(all_results)} successful, {len(failed_experiments)} failed\")\n\nif failed_experiments:\n    print(f\"\\nâš ï¸ Failed experiments:\")\n    for name in failed_experiments:\n        print(f\"   â€¢ {name}\")\n\n# Create summary report\nif all_results:\n    print(f\"\\n{'='*80}\")\n    print(\"CREATING SUMMARY REPORT\")\n    print(f\"{'='*80}\\n\")\n    \n    summary_df = pd.DataFrame(all_results)\n    summary_df = summary_df.sort_values('best_val_f1_macro', ascending=False)\n    \n    # Display summary table\n    print(\"ðŸ“Š EXPERIMENT SUMMARY (sorted by validation F1 Macro):\\n\")\n    display_cols = [\n        'name', \n        'best_val_f1_macro', \n        'best_epoch',\n        'train_val_gap',\n        'total_epochs'\n    ]\n    print(summary_df[display_cols].to_string(index=False))\n    \n    # Save detailed summary\n    summary_path = os.path.join(output_dir, 'experiments_summary.csv')\n    summary_df.to_csv(summary_path, index=False)\n    print(f\"\\nâœ… Detailed summary saved to: {summary_path}\")\n    \n    # Display best model\n    best_experiment = summary_df.iloc[0]\n    print(f\"\\n{'='*80}\")\n    print(\"ðŸ† BEST MODEL\")\n    print(f\"{'='*80}\")\n    print(f\"Name: {best_experiment['name']}\")\n    print(f\"Best Val F1 Macro: {best_experiment['best_val_f1_macro']:.4f}\")\n    print(f\"Best Epoch: {best_experiment['best_epoch']}\")\n    print(f\"Best Val Accuracy: {best_experiment['best_val_acc']:.4f}\")\n    print(f\"Train-Val Gap: {best_experiment['train_val_gap']:.4f}\")\n    print(f\"Total Epochs: {best_experiment['total_epochs']}\")\n    print(f\"\\nFiles:\")\n    print(f\"  â€¢ Model: {best_experiment['model_path']}\")\n    print(f\"  â€¢ Offsite submission: {best_experiment['offsite_submission']}\")\n    print(f\"  â€¢ Onsite submission: {best_experiment['onsite_submission']}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Show top 3 models\n    if len(summary_df) >= 3:\n        print(\"ðŸ¥‡ TOP 3 MODELS:\\n\")\n        for idx, row in summary_df.head(3).iterrows():\n            rank = ['ðŸ¥‡', 'ðŸ¥ˆ', 'ðŸ¥‰'][list(summary_df.head(3).index).index(idx)]\n            print(f\"{rank} {row['name']}\")\n            print(f\"   Val F1: {row['best_val_f1_macro']:.4f} | Epoch: {row['best_epoch']} | Gap: {row['train_val_gap']:.4f}\")\n            print()\n    \n    # Performance distribution\n    print(\"\\nðŸ“ˆ PERFORMANCE DISTRIBUTION:\")\n    print(f\"   Best Val F1: {summary_df['best_val_f1_macro'].max():.4f}\")\n    print(f\"   Worst Val F1: {summary_df['best_val_f1_macro'].min():.4f}\")\n    print(f\"   Mean Val F1: {summary_df['best_val_f1_macro'].mean():.4f}\")\n    print(f\"   Std Val F1: {summary_df['best_val_f1_macro'].std():.4f}\")\n    \n    # Training efficiency\n    print(\"\\nâ±ï¸ TRAINING EFFICIENCY:\")\n    print(f\"   Avg epochs to best: {summary_df['best_epoch'].mean():.1f}\")\n    print(f\"   Avg total epochs: {summary_df['total_epochs'].mean():.1f}\")\n    print(f\"   Avg train-val gap: {summary_df['train_val_gap'].mean():.4f}\")\n    \n    # Create comparison plot\n    print(f\"\\n{'='*80}\")\n    print(\"CREATING COMPARISON PLOTS\")\n    print(f\"{'='*80}\\n\")\n    \n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Bar plot of Val F1 scores\n    axes[0].barh(summary_df['name'], summary_df['best_val_f1_macro'], color='skyblue')\n    axes[0].set_xlabel('Best Validation F1 Macro', fontsize=12)\n    axes[0].set_title('Model Comparison - Validation F1 Macro', fontsize=14, fontweight='bold')\n    axes[0].grid(axis='x', alpha=0.3)\n    \n    # Add value labels\n    for i, (name, val) in enumerate(zip(summary_df['name'], summary_df['best_val_f1_macro'])):\n        axes[0].text(val, i, f' {val:.4f}', va='center', fontsize=10)\n    \n    # Scatter plot: Train-Val Gap vs Performance\n    scatter = axes[1].scatter(\n        summary_df['train_val_gap'], \n        summary_df['best_val_f1_macro'],\n        s=100,\n        c=summary_df['best_epoch'],\n        cmap='viridis',\n        alpha=0.7\n    )\n    axes[1].set_xlabel('Train-Val F1 Gap', fontsize=12)\n    axes[1].set_ylabel('Best Val F1 Macro', fontsize=12)\n    axes[1].set_title('Overfitting vs Performance', fontsize=14, fontweight='bold')\n    axes[1].grid(True, alpha=0.3)\n    \n    # Add colorbar\n    cbar = plt.colorbar(scatter, ax=axes[1])\n    cbar.set_label('Best Epoch', fontsize=10)\n    \n    # Add model labels\n    for idx, row in summary_df.iterrows():\n        axes[1].annotate(\n            row['name'].replace('_optimal', ''),\n            (row['train_val_gap'], row['best_val_f1_macro']),\n            fontsize=8,\n            alpha=0.7,\n            xytext=(5, 5),\n            textcoords='offset points'\n        )\n    \n    plt.tight_layout()\n    comparison_plot_path = os.path.join(output_dir, 'model_comparison.png')\n    plt.savefig(comparison_plot_path, dpi=150, bbox_inches='tight')\n    plt.show()\n    plt.close()\n    \n    print(f\"âœ… Comparison plot saved to: {comparison_plot_path}\")\n    \nelse:\n    print(\"\\nâŒ No experiments completed successfully!\")\n    print(\"Please check the error messages above.\")\n\nprint(f\"\\n{'#'*80}\")\nprint(\"EXPERIMENT EXECUTION COMPLETE\")\nprint(f\"{'#'*80}\\n\")\n\n# Save execution log\nlog_path = os.path.join(output_dir, 'execution_log.txt')\nwith open(log_path, 'w') as f:\n    f.write(\"EXPERIMENT EXECUTION LOG\\n\")\n    f.write(\"=\"*80 + \"\\n\\n\")\n    f.write(f\"Total experiments: {len(experiments)}\\n\")\n    f.write(f\"Successful: {len(all_results)}\\n\")\n    f.write(f\"Failed: {len(failed_experiments)}\\n\\n\")\n    \n    if all_results:\n        f.write(\"RESULTS:\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        for result in all_results:\n            f.write(f\"\\n{result['name']}:\\n\")\n            f.write(f\"  Best Val F1: {result['best_val_f1_macro']:.4f}\\n\")\n            f.write(f\"  Best Epoch: {result['best_epoch']}\\n\")\n            f.write(f\"  Train-Val Gap: {result['train_val_gap']:.4f}\\n\")\n    \n    if failed_experiments:\n        f.write(\"\\n\\nFAILED EXPERIMENTS:\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        for name in failed_experiments:\n            f.write(f\"  â€¢ {name}\\n\")\n\nprint(f\"âœ… Execution log saved to: {log_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T09:07:05.023785Z","iopub.execute_input":"2025-12-31T09:07:05.024093Z","iopub.status.idle":"2025-12-31T09:07:58.462625Z","shell.execute_reply.started":"2025-12-31T09:07:05.024067Z","shell.execute_reply":"2025-12-31T09:07:58.461994Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nSTARTING ALL EXPERIMENTS\n################################################################################\n\nVerifying required variables...\nâœ… train_csv: OK\nâœ… val_csv: OK\nâœ… offsite_test_csv: OK\nâœ… onsite_test_img_dir: OK\nâœ… train_img_dir: OK\nâœ… val_img_dir: OK\nâœ… offsite_test_img_dir: OK\nâœ… train_transform: OK\nâœ… val_transform: OK\nâœ… class_weights: OK\nâœ… device: OK\nâœ… output_dir: OK\n\n================================================================================\nRunning 5 experiments\nOutput directory: /kaggle/working/task_4_3_experiment_results__final__\n================================================================================\n\n\n################################################################################\nSTARTING EXPERIMENT 1/5: vit_base_v6\n################################################################################\n\n================================================================================\nEXPERIMENT 1/5: vit_base_v6\n================================================================================\nBackbone: vit_base_patch16_224\nDropout: 0.2\nLearning Rate: 0.0001\nWeight Decay: 0.001\nBatch Size: 24\nFine-tuning: Epoch 25\nMixUp: Yes (alpha=0.2)\nFocal Loss: No\nLabel Smoothing: 0.0\nScheduler: plateau\n================================================================================\n\nDataset sizes:\n  Train: 800\n  Validation: 200\n  Offsite Test: 200\n  Onsite Test: 250\n\n\n======================================================================\nCreating model: vit_base_patch16_224\n======================================================================\nTrainable parameters: 98,819\nSE blocks: Enabled\nDropout: 0.2\n======================================================================\n\nModel parameters:\n  Total: 85,897,475\n  Trainable (initial): 98,819\n\nâœ… Using Focal Loss + Label Smoothing\nâœ… Using Cosine Annealing LR\n\n======================================================================\nOPTIMIZED TRAINING CONFIGURATION\n======================================================================\nModel: vit_base_v6\nEpochs: 100\nLearning Rate: 0.0001\nWeight Decay: 0.001 (STRONG!)\nFine-tuning starts: Epoch 25\nEarly Stopping Patience: 20\nMixUp: Enabled (alpha=0.2, prob=0.5)\nGradient Clipping: 1.0\nLabel Smoothing: 0.1\nFocal Loss: Enabled\nScheduler: cosine\nClass Weights: [0.5473888 3.9079754 4.633803 ]\n======================================================================\n\n\nEpoch 1/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 3.7320 | Val Loss: 1.9396\nTrain F1: 0.3955 | Val F1: 0.4317\nTrain Acc: 0.5133 | Val Acc: 0.5033\nLearning Rate: 0.000100\nTrain-Val F1 Gap: 0.0362\nâœ… New best Val F1: 0.4317\nâœ… Model saved to /kaggle/working/task_4_3_experiment_results__final__/vit_base_v6_best.pth\n\nEpoch 2/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.8552 | Val Loss: 1.6201\nTrain F1: 0.4079 | Val F1: 0.5000\nTrain Acc: 0.5417 | Val Acc: 0.6050\nLearning Rate: 0.000100\nTrain-Val F1 Gap: 0.0921\nâœ… New best Val F1: 0.5000\nâœ… Model saved to /kaggle/working/task_4_3_experiment_results__final__/vit_base_v6_best.pth\n\nEpoch 3/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.6497 | Val Loss: 1.5060\nTrain F1: 0.3897 | Val F1: 0.5194\nTrain Acc: 0.5179 | Val Acc: 0.6267\nLearning Rate: 0.000100\nTrain-Val F1 Gap: 0.1298\nâœ… New best Val F1: 0.5194\nâœ… Model saved to /kaggle/working/task_4_3_experiment_results__final__/vit_base_v6_best.pth\n\nEpoch 4/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.2659 | Val Loss: 1.6108\nTrain F1: 0.4194 | Val F1: 0.5176\nTrain Acc: 0.5667 | Val Acc: 0.6600\nLearning Rate: 0.000100\nTrain-Val F1 Gap: 0.0982\n\nEpoch 5/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.1583 | Val Loss: 1.3306\nTrain F1: 0.4214 | Val F1: 0.5319\nTrain Acc: 0.5704 | Val Acc: 0.6417\nLearning Rate: 0.000100\nTrain-Val F1 Gap: 0.1105\nâœ… New best Val F1: 0.5319\nâœ… Model saved to /kaggle/working/task_4_3_experiment_results__final__/vit_base_v6_best.pth\n\nEpoch 6/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.0689 | Val Loss: 1.2047\nTrain F1: 0.4403 | Val F1: 0.5326\nTrain Acc: 0.5858 | Val Acc: 0.6400\nLearning Rate: 0.000099\nTrain-Val F1 Gap: 0.0922\nâœ… New best Val F1: 0.5326\nâœ… Model saved to /kaggle/working/task_4_3_experiment_results__final__/vit_base_v6_best.pth\n\nEpoch 7/100 [TRANSFER LEARNING]\n----------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"\n\nâš ï¸ Training interrupted by user!\nCompleted 0/5 experiments\n\n================================================================================\nPROGRESS: 0 successful, 0 failed, 4 remaining\n================================================================================\n\n\n################################################################################\nALL EXPERIMENTS COMPLETED!\n################################################################################\n\nResults: 0 successful, 0 failed\n\nâŒ No experiments completed successfully!\nPlease check the error messages above.\n\n################################################################################\nEXPERIMENT EXECUTION COMPLETE\n################################################################################\n\nâœ… Execution log saved to: /kaggle/working/task_4_3_experiment_results__final__/execution_log.txt\n","output_type":"stream"}],"execution_count":93},{"id":"1f4626c8","cell_type":"code","source":"# ============================================================================\n# ENSEMBLE OF BEST 3 MODELS\n# ============================================================================\n\ndef ensemble_predict(models, test_loader, device, weights=None):\n    \"\"\"\n    Ensemble prediction using multiple models\n    weights: optional weights for each model (default: equal weights)\n    \"\"\"\n    if weights is None:\n        weights = [1.0 / len(models)] * len(models)\n    \n    all_predictions = []\n    all_filenames = []\n    \n    # Set all models to eval mode\n    for model in models:\n        model.eval()\n    \n    with torch.no_grad():\n        pbar = tqdm(test_loader, desc='Ensemble predictions')\n        for images, labels, filenames in pbar:\n            images = images.to(device)\n            \n            # Get predictions from all models\n            batch_predictions = []\n            for model, weight in zip(models, weights):\n                outputs = model(images)\n                predictions = torch.sigmoid(outputs).cpu().numpy()\n                batch_predictions.append(predictions * weight)\n            \n            # Average predictions\n            ensemble_pred = np.sum(batch_predictions, axis=0)\n            all_predictions.append(ensemble_pred)\n            all_filenames.extend(filenames)\n    \n    predictions = np.vstack(all_predictions)\n    predictions_binary = (predictions > 0.5).astype(int)\n    \n    return all_filenames, predictions_binary, predictions\n\n\ndef evaluate_ensemble(models, val_loader, device, weights=None):\n    \"\"\"Evaluate ensemble on validation set\"\"\"\n    if weights is None:\n        weights = [1.0 / len(models)] * len(models)\n    \n    all_labels = []\n    all_predictions = []\n    \n    for model in models:\n        model.eval()\n    \n    with torch.no_grad():\n        pbar = tqdm(val_loader, desc='Ensemble evaluation')\n        for images, labels, _ in pbar:\n            images = images.to(device)\n            \n            batch_predictions = []\n            for model, weight in zip(models, weights):\n                outputs = model(images)\n                predictions = torch.sigmoid(outputs).cpu().numpy()\n                batch_predictions.append(predictions * weight)\n            \n            ensemble_pred = np.sum(batch_predictions, axis=0)\n            all_predictions.append(ensemble_pred)\n            all_labels.append(labels.cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_predictions = np.vstack(all_predictions)\n    \n    metrics = calculate_metrics(all_labels, all_predictions)\n    return metrics\n\n\nprint(\"âœ… Ensemble prediction functions ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T06:02:07.496638Z","iopub.execute_input":"2025-12-31T06:02:07.497361Z","iopub.status.idle":"2025-12-31T06:02:07.506938Z","shell.execute_reply.started":"2025-12-31T06:02:07.497332Z","shell.execute_reply":"2025-12-31T06:02:07.506113Z"}},"outputs":[{"name":"stdout","text":"âœ… Ensemble prediction functions ready\n","output_type":"stream"}],"execution_count":22},{"id":"e1efb2a6-14fd-4e47-b15e-1e5febfb8e65","cell_type":"code","source":"# # ============================================================================\n# # MINIMAL VERSION: TRAIN ON OFFSITE TEST DATASET\n# # ============================================================================\n#  # Options: 'vit_base_patch16_224', 'resnet50', 'densenet121',\n# # Configuration\n# PRETRAINED_MODEL = \"/kaggle/working/task_4_3_experiment_results__final/densenet121_finetuned_v6_best.pth\"  # or None\n# MODEL_BACKBONE = 'densenet121'\n# NUM_EPOCHS = 15\n# LEARNING_RATE = 1e-5\n# OUTPUT_MODEL = f\"/kaggle/working/{MODEL_BACKBONE}_offsite_trained.pth\"\n\n# # Prepare data\n# offsite_dataset = RetinaMultiLabelDataset(\n#     \"/kaggle/working/final_project_resources/offsite_test.csv\",\n#     \"/kaggle/working/final_project_resources/images/offsite_test\",\n#     transform=train_transform\n# )\n# train_loader = DataLoader(offsite_dataset, batch_size=32, shuffle=True, num_workers=0)\n\n# print(f\"Training on {len(offsite_dataset)} offsite images for {NUM_EPOCHS} epochs\")\n\n# # Create/load model\n# model = create_model(MODEL_BACKBONE, 3, 0.3, True, device, torch.cuda.device_count() > 1)\n\n# if PRETRAINED_MODEL:\n#     checkpoint = torch.load(PRETRAINED_MODEL, weights_only=False)\n#     if isinstance(model, nn.DataParallel):\n#         model.module.load_state_dict(checkpoint['model_state_dict'])\n#     else:\n#         model.load_state_dict(checkpoint['model_state_dict'])\n#     print(\"âœ… Loaded pretrained weights\")\n\n# # Setup training\n# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n# # Calculate class weights directly on device\n# offsite_df = pd.read_csv(\"/kaggle/working/final_project_resources/offsite_test.csv\")\n# total = len(offsite_df)\n# class_counts = torch.tensor([\n#     offsite_df['D'].sum(),\n#     offsite_df['G'].sum(), \n#     offsite_df['A'].sum()\n# ], dtype=torch.float32)\n\n# # Create class weights on device\n# class_weights_new = (total - class_counts) / class_counts\n# class_weights_new = class_weights_new.to(device)\n\n# criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_new)\n# # Training loop\n# best_f1 = 0.0\n# history = {'loss': [], 'f1': [], 'acc': []}\n\n# for epoch in range(NUM_EPOCHS):\n#     model.train()\n#     epoch_loss, all_preds, all_labels = 0.0, [], []\n    \n#     for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n#         images, labels = images.to(device), labels.to(device)\n        \n#         optimizer.zero_grad()\n#         outputs = model(images)\n#         loss = criterion(outputs, labels)\n#         loss.backward()\n#         optimizer.step()\n        \n#         epoch_loss += loss.item()\n#         all_preds.append((torch.sigmoid(outputs) > 0.5).float().cpu().numpy())\n#         all_labels.append(labels.cpu().numpy())\n    \n#     # Metrics\n#     all_preds = np.vstack(all_preds)\n#     all_labels = np.vstack(all_labels)\n#     avg_loss = epoch_loss / len(train_loader)\n#     f1 = f1_score(all_labels, all_preds, average='macro')\n#     acc = accuracy_score(all_labels, all_preds)\n    \n#     history['loss'].append(avg_loss)\n#     history['f1'].append(f1)\n#     history['acc'].append(acc)\n    \n#     print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, F1={f1:.4f}, Acc={acc:.4f}\")\n    \n#     # Save best\n#     if f1 > best_f1:\n#         best_f1 = f1\n#         state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n#         torch.save({'model_state_dict': state_dict, 'best_f1': best_f1}, OUTPUT_MODEL)\n#         print(f\"  ðŸ† New best! Saved to {OUTPUT_MODEL}\")\n    \n#     torch.cuda.empty_cache()\n\n# print(f\"\\nâœ… Training complete! Best F1: {best_f1:.4f}\")\n# print(f\"âœ… Model saved: {OUTPUT_MODEL}\")\n\n# # Plot\n# plt.figure(figsize=(12, 4))\n# plt.subplot(131); plt.plot(history['loss']); plt.title('Loss'); plt.grid()\n# plt.subplot(132); plt.plot(history['f1']); plt.title('F1 Macro'); plt.grid()\n# plt.subplot(133); plt.plot(history['acc']); plt.title('Accuracy'); plt.grid()\n# plt.tight_layout()\n# plt.savefig(f'/kaggle/working/{MODEL_BACKBONE}_offsite_history.png')\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T09:37:08.023121Z","iopub.execute_input":"2025-12-31T09:37:08.023754Z","iopub.status.idle":"2025-12-31T09:37:21.570528Z","shell.execute_reply.started":"2025-12-31T09:37:08.023721Z","shell.execute_reply":"2025-12-31T09:37:21.569783Z"}},"outputs":[{"name":"stdout","text":"Training on 200 offsite images for 15 epochs\n\n======================================================================\nCreating model: densenet121\n======================================================================\nTrainable parameters: 262,659\nSE blocks: Enabled\nDropout: 0.3\n======================================================================\n\nâœ… Loaded pretrained weights\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss=0.7206, F1=0.6440, Acc=0.6200\n  ðŸ† New best! Saved to /kaggle/working/densenet121_offsite_trained.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss=0.6861, F1=0.6508, Acc=0.6300\n  ðŸ† New best! Saved to /kaggle/working/densenet121_offsite_trained.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss=0.7428, F1=0.6185, Acc=0.5900\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss=0.6950, F1=0.6277, Acc=0.5800\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss=0.6906, F1=0.6273, Acc=0.6150\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss=0.6452, F1=0.6349, Acc=0.6200\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss=0.6615, F1=0.6342, Acc=0.6300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss=0.7097, F1=0.6454, Acc=0.6400\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss=0.6267, F1=0.6441, Acc=0.6300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss=0.8909, F1=0.6387, Acc=0.6050\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss=0.7245, F1=0.6470, Acc=0.6250\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss=0.7024, F1=0.6416, Acc=0.5950\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss=0.7824, F1=0.6385, Acc=0.6100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss=0.6574, F1=0.6794, Acc=0.6450\n  ðŸ† New best! Saved to /kaggle/working/densenet121_offsite_trained.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss=0.7071, F1=0.6529, Acc=0.6250\n\nâœ… Training complete! Best F1: 0.6794\nâœ… Model saved: /kaggle/working/densenet121_offsite_trained.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 3 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":110},{"id":"d4ef0915-6147-4b42-bc77-ce0f0d280f97","cell_type":"code","source":"# # ============================================================================\n# # QUICK SCRIPT: LOAD .PTH MODEL AND GENERATE CSV PREDICTIONS\n# # Copy-paste this into a Jupyter notebook cell\n# # ============================================================================\n\n# # ============================================================================\n# # STEP 1: CONFIGURE THESE SETTINGS\n# # ============================================================================\n\n# # Path to your saved model\n# MODEL_PATH = \"/kaggle/working/downloaded_file.pth\"\n\n# # Model configuration (must match the model you saved)\n# MODEL_BACKBONE = 'resnet18'  # Options: 'vit_base_patch16_224', 'resnet50', 'densenet121', 'efficientnet_b0'\n# MODEL_DROPOUT = 0.4\n# MODEL_USE_SE = True\n\n# # Output path\n# OUTPUT_CSV = f\"/kaggle/working/{MODEL_BACKBONE}.csv\"\n\n# # ============================================================================\n# # STEP 2: PREPARE ONSITE TEST DATA\n# # ============================================================================\n\n# print(\"Preparing onsite test dataset...\")\n\n# # Get test image files\n# onsite_test_dir = \"/kaggle/working/final_project_resources/images/onsite_test\"\n# onsite_files = sorted([f for f in os.listdir(onsite_test_dir) if f.endswith(('.jpg', '.png'))])\n\n# print(f\"Found {len(onsite_files)} test images\")\n\n# # Create temp CSV\n# temp_df = pd.DataFrame({\n#     'id': onsite_files,\n#     'D': [0] * len(onsite_files),\n#     'G': [0] * len(onsite_files),\n#     'A': [0] * len(onsite_files)\n# })\n# temp_csv = 'temp_onsite.csv'\n# temp_df.to_csv(temp_csv, index=False)\n\n# # Create dataset\n# test_dataset = RetinaMultiLabelDataset(temp_csv, onsite_test_dir, transform=val_transform)\n# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n\n# print(f\"âœ… Dataset ready: {len(test_dataset)} images\")\n\n# # ============================================================================\n# # STEP 3: LOAD MODEL\n# # ============================================================================\n\n# print(f\"\\nLoading model from: {MODEL_PATH}\")\n\n# # Create model architecture\n# model = create_model(\n#     backbone_name=MODEL_BACKBONE,\n#     num_classes=3,\n#     dropout=MODEL_DROPOUT,\n#     use_se=MODEL_USE_SE,\n#     device=device,\n#     multi_gpu=torch.cuda.device_count() > 1\n# )\n\n# # Load weights\n# checkpoint = torch.load(MODEL_PATH, weights_only=False, map_location=device)\n\n# if isinstance(model, nn.DataParallel):\n#     model.module.load_state_dict(checkpoint['model_state_dict'])\n# else:\n#     model.load_state_dict(checkpoint['model_state_dict'])\n\n# print(\"âœ… Model loaded successfully\")\n\n# # ============================================================================\n# # STEP 4: GENERATE PREDICTIONS\n# # ============================================================================\n\n# print(\"\\nGenerating predictions...\")\n\n# model.eval()\n# all_filenames = []\n# all_predictions = []\n\n# with torch.no_grad():\n#     for images, _, filenames in tqdm(test_loader, desc=\"Predicting\"):\n#         images = images.to(device)\n#         outputs = model(images)\n#         predictions = (torch.sigmoid(outputs) > 0.5).float()\n        \n#         all_filenames.extend(filenames)\n#         all_predictions.append(predictions.cpu().numpy())\n\n# all_predictions = np.vstack(all_predictions)\n\n# print(f\"âœ… Generated {len(all_predictions)} predictions\")\n\n# # ============================================================================\n# # STEP 5: SAVE TO CSV\n# # ============================================================================\n\n# print(\"\\nSaving submission...\")\n\n# submission_df = pd.DataFrame({\n#     'id': all_filenames,\n#     'D': all_predictions[:, 0].astype(int),\n#     'G': all_predictions[:, 1].astype(int),\n#     'A': all_predictions[:, 2].astype(int)\n# })\n\n# submission_df.to_csv(OUTPUT_CSV, index=False)\n\n# print(f\"âœ… Submission saved to: {OUTPUT_CSV}\")\n# print(f\"\\nðŸ“‹ First 5 predictions:\")\n# print(submission_df.head())\n\n# print(f\"\\nðŸ“Š Prediction distribution:\")\n# print(f\"  D (DR): {submission_df['D'].sum()} positive ({submission_df['D'].mean()*100:.1f}%)\")\n# print(f\"  G (Glaucoma): {submission_df['G'].sum()} positive ({submission_df['G'].mean()*100:.1f}%)\")\n# print(f\"  A (AMD): {submission_df['A'].sum()} positive ({submission_df['A'].mean()*100:.1f}%)\")\n\n# # Cleanup\n# os.remove(temp_csv)\n\n# print(\"\\nâœ… DONE!\")\n\n# # ============================================================================\n# # BONUS: BATCH PROCESS MULTIPLE MODELS\n# # ============================================================================\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":1},{"id":"24a6560e-5cc4-48c2-97af-080bf8b61342","cell_type":"code","source":"# # ============================================================================\n# # CREATE ENSEMBLE AND GENERATE FINAL PREDICTIONS\n# # ============================================================================\n\n# print(\"\\n\" + \"=\"*80)\n# print(\"CREATING ENSEMBLE OF BEST 3 MODELS\")\n# print(\"=\"*80)\n\n# if len(all_results) >= 3:\n#     # Select best 3 models based on validation F1 Macro\n#     summary_df = pd.DataFrame(all_results)\n#     summary_df = summary_df.sort_values('best_val_f1_macro', ascending=False)\n#     best_3_models = summary_df.head(3)\n    \n#     print(\"\\nðŸ† Best 3 models selected for ensemble:\")\n#     for idx, row in best_3_models.iterrows():\n#         print(f\"   {row['name']}: Val F1 Macro = {row['best_val_f1_macro']:.4f}\")\n    \n#     # Load the best 3 models\n#     ensemble_models = []\n#     for idx, row in best_3_models.iterrows():\n#         print(f\"\\nLoading {row['name']}...\")\n#         checkpoint = torch.load(row['model_path'], map_location=device, weights_only=False)\n        \n#         # Extract backbone name from model name\n#         backbone_map = {\n#             'resnet50': 'resnet50',\n#             'densenet121': 'densenet121',\n#             'inception_v3': 'inception_v3',\n#             'shufflenet_v2': 'shufflenet_v2',\n#             'vit_base': 'vit_base_patch16_224'\n#         }\n        \n#         backbone_name = None\n#         for key in backbone_map:\n#             if key in row['name']:\n#                 backbone_name = backbone_map[key]\n#                 break\n        \n#         if backbone_name is None:\n#             print(f\"âš ï¸ Could not determine backbone for {row['name']}, skipping...\")\n#             continue\n        \n#         model = create_model(backbone_name, num_classes=3, dropout=0.5)\n#         model.load_state_dict(checkpoint['model_state_dict'])\n#         model.eval()\n#         ensemble_models.append(model)\n#         print(f\"âœ… Loaded {row['name']}\")\n    \n#     if len(ensemble_models) == 3:\n#         print(f\"\\nâœ… Successfully loaded {len(ensemble_models)} models for ensemble\")\n        \n#         # Evaluate ensemble on validation set\n#         print(\"\\n\" + \"=\"*70)\n#         print(\"EVALUATING ENSEMBLE ON VALIDATION SET\")\n#         print(\"=\"*70)\n        \n#         val_dataset = RetinaMultiLabelDataset(val_csv, val_img_dir, transform=val_transform)\n#         val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n        \n#         ensemble_metrics = evaluate_ensemble(ensemble_models, val_loader, device)\n        \n#         print(\"\\nðŸ“Š ENSEMBLE VALIDATION RESULTS:\")\n#         print(f\"  F1 Macro: {ensemble_metrics['f1_macro']:.4f}\")\n#         print(f\"  F1 Micro: {ensemble_metrics['f1_micro']:.4f}\")\n#         print(f\"  Mean Accuracy: {ensemble_metrics['mean_accuracy']:.4f}\")\n#         print(f\"  Mean Precision: {ensemble_metrics['mean_precision']:.4f}\")\n#         print(f\"  Mean Recall: {ensemble_metrics['mean_recall']:.4f}\")\n        \n#         disease_names = ['D (DR)', 'G (Glaucoma)', 'A (AMD)']\n#         print(\"\\n  Per-class metrics:\")\n#         for i, disease in enumerate(disease_names):\n#             print(f\"    {disease}:\")\n#             print(f\"      F1: {ensemble_metrics['per_class_f1'][i]:.4f}\")\n#             print(f\"      Precision: {ensemble_metrics['per_class_precision'][i]:.4f}\")\n#             print(f\"      Recall: {ensemble_metrics['per_class_recall'][i]:.4f}\")\n        \n#         # Generate ensemble predictions for onsite test\n#         print(\"\\n\" + \"=\"*70)\n#         print(\"GENERATING ENSEMBLE PREDICTIONS FOR ONSITE TEST\")\n#         print(\"=\"*70)\n        \n#         onsite_test_files = sorted([f for f in os.listdir(onsite_test_img_dir) if f.endswith(('.jpg', '.png'))])\n#         onsite_test_data = pd.DataFrame({\n#             'id': onsite_test_files,\n#             'D': [0] * len(onsite_test_files),\n#             'G': [0] * len(onsite_test_files),\n#             'A': [0] * len(onsite_test_files)\n#         })\n#         onsite_test_csv_temp = os.path.join(output_dir, 'temp_onsite_ensemble.csv')\n#         onsite_test_data.to_csv(onsite_test_csv_temp, index=False)\n#         onsite_test_dataset = RetinaMultiLabelDataset(onsite_test_csv_temp, onsite_test_img_dir, transform=val_transform)\n#         onsite_test_loader = DataLoader(onsite_test_dataset, batch_size=32, shuffle=False, num_workers=0)\n        \n#         onsite_filenames, onsite_predictions, onsite_probs = ensemble_predict(ensemble_models, onsite_test_loader, device)\n        \n#         # Save ensemble predictions\n#         ensemble_submission_path = os.path.join(output_dir, 'ensemble_best3_onsite_submission.csv')\n#         ensemble_submission = create_submission(onsite_filenames, onsite_predictions, ensemble_submission_path)\n        \n#         # Clean up\n#         if os.path.exists(onsite_test_csv_temp):\n#             os.remove(onsite_test_csv_temp)\n        \n#         # Save ensemble validation results\n#         ensemble_val_results = {\n#             'ensemble_models': [row['name'] for _, row in best_3_models.iterrows()],\n#             'val_f1_macro': ensemble_metrics['f1_macro'],\n#             'val_f1_micro': ensemble_metrics['f1_micro'],\n#             'val_accuracy': ensemble_metrics['mean_accuracy'],\n#             'val_precision': ensemble_metrics['mean_precision'],\n#             'val_recall': ensemble_metrics['mean_recall']\n#         }\n        \n#         ensemble_results_path = os.path.join(output_dir, 'ensemble_validation_results.csv')\n#         pd.DataFrame([ensemble_val_results]).to_csv(ensemble_results_path, index=False)\n        \n#         print(\"\\nâœ… ENSEMBLE COMPLETE!\")\n#         print(f\"   Ensemble validation results: {ensemble_results_path}\")\n#         print(f\"   Ensemble onsite submission: {ensemble_submission_path}\")\n#         print(f\"   Ensemble Val F1 Macro: {ensemble_metrics['f1_macro']:.4f}\")\n        \n#     else:\n#         print(f\"\\nâš ï¸ Could not load all 3 models for ensemble\")\n# else:\n#     print(\"\\nâš ï¸ Not enough models completed successfully for ensemble (need at least 3)\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c1cb7b84-0601-439c-a4aa-078113965d58","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}